{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SageMaker SDK Training & Hyperparameter Tuning\n\n**Lab 3 - Assignments 2 & 3 Answer Notebook**\n\nThis notebook demonstrates model training and hyperparameter tuning using the SageMaker Python SDK, answering:\n- **Assignment 2**: Training with Framework Estimators\n- **Assignment 3**: Hyperparameter Tuning with the SDK\n\n**Key Benefits of SDK Approach:**\n- 80% less code compared to sagemaker-core\n- High-level ML abstractions (Estimators, Tuners, Predictors)\n- Automatic handling of AWS resource configuration\n- Clean inference with automatic serialization\n- Integrated hyperparameter tuning workflow"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "We'll use our existing `CoreLabSession` for session management but switch to SageMaker SDK for ML operations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T18:05:15.195726Z",
     "start_time": "2025-10-12T18:05:12.717648Z"
    }
   },
   "source": [
    "from corelab.core.session import CoreLabSession\n",
    "\n",
    "# Use our custom session for authentication and S3 management\n",
    "lab_session = CoreLabSession('pytorch', 'customer-churn',\n",
    "                            default_folder='sagemaker_sdk_notebook', \n",
    "                            create_run_folder=True,\n",
    "                             aws_profile='sagemaker-role')\n",
    "lab_session.print()\n",
    "\n",
    "# Get SageMaker session for SDK integration\n",
    "sagemaker_session = lab_session.get_sagemaker_session()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution role available: arn:aws:iam::136548476532:role/service-role/AmazonSageMaker-ExecutionRole-20250902T164316\n",
      "AWS region: eu-central-1\n",
      "Execution role arn:aws:iam::136548476532:role/service-role/AmazonSageMaker-ExecutionRole-20250902T164316\n",
      "Output bucket uri: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13\n",
      "Framework: pytorch\n",
      "Project name: customer-churn\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Same data preparation as the core notebook - this part doesn't change."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T18:05:18.971288Z",
     "start_time": "2025-10-12T18:05:18.641153Z"
    }
   },
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = lab_session.core_session.read_s3_file(\n",
    "    f\"sagemaker-example-files-prod-{lab_session.region}\", \n",
    "    \"datasets/tabular/synthetic/churn.txt\"\n",
    ")\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Churn rate: {df['Churn?'].value_counts(normalize=True)['True.']:.1%}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5000, 21)\n",
      "Churn rate: 50.0%\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T18:05:20.489707Z",
     "start_time": "2025-10-12T18:05:20.435664Z"
    }
   },
   "source": [
    "# Data preprocessing\n",
    "df = df.drop(\"Phone\", axis=1)  # Remove unique identifier\n",
    "df[\"Area Code\"] = df[\"Area Code\"].astype(object)  # Treat as categorical\n",
    "\n",
    "# Remove highly correlated features (charges are derived from minutes)\n",
    "df = df.drop([\"Day Charge\", \"Eve Charge\", \"Night Charge\", \"Intl Charge\"], axis=1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "model_data = pd.get_dummies(df)\n",
    "\n",
    "# Move target to first column (XGBoost convention)\n",
    "model_data = pd.concat([\n",
    "    model_data[\"Churn?_True.\"],\n",
    "    model_data.drop([\"Churn?_False.\", \"Churn?_True.\"], axis=1),\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Processed data shape: {model_data.shape}\")\n",
    "print(f\"Features: {model_data.shape[1] - 1}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (5000, 100)\n",
      "Features: 99\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T18:05:22.527864Z",
     "start_time": "2025-10-12T18:05:21.693745Z"
    }
   },
   "source": [
    "# Split into train/validation/test\n",
    "train_data, temp_data = train_test_split(model_data, test_size=0.33, random_state=42)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"Train: {train_data.shape[0]} samples\")\n",
    "print(f\"Validation: {validation_data.shape[0]} samples\") \n",
    "print(f\"Test: {test_data.shape[0]} samples\")\n",
    "\n",
    "# Save and upload datasets\n",
    "train_data.to_csv(\"train.csv\", header=False, index=False)\n",
    "validation_data.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "# Store test target separately for evaluation\n",
    "test_target = test_data.iloc[:, 0]  # First column is target\n",
    "test_features = test_data.iloc[:, 1:]  # Rest are features\n",
    "test_features.to_csv(\"test.csv\", header=False, index=False)\n",
    "\n",
    "# Upload to S3\n",
    "s3_train_path = lab_session.core_session.upload_data(\"train.csv\")\n",
    "s3_validation_path = lab_session.core_session.upload_data(\"validation.csv\")\n",
    "s3_test_path = lab_session.core_session.upload_data(\"test.csv\")\n",
    "\n",
    "print(f\"\\nData uploaded to S3:\")\n",
    "print(f\"Train: {s3_train_path}\")\n",
    "print(f\"Validation: {s3_validation_path}\")\n",
    "print(f\"Test: {s3_test_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3350 samples\n",
      "Validation: 1105 samples\n",
      "Test: 545 samples\n",
      "\n",
      "Data uploaded to S3:\n",
      "Train: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13/data/train.csv\n",
      "Validation: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13/data/validation.csv\n",
      "Test: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13/data/test.csv\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üéì Assignment 2: Training with Framework Estimators\n\nThis section demonstrates training with the **PyTorch Framework Estimator** with a custom XGBoost training script - the modern, flexible approach (Lab 3 Option A - Recommended).\n\n**What You'll Learn:**\n- Using PyTorch Framework Estimator for custom training logic\n- Running XGBoost within PyTorch container (modern Python ecosystem)\n- Creating custom training scripts with SageMaker conventions\n- Passing hyperparameters as command-line arguments\n- Automatic dependency installation via requirements.txt\n\n**Key Approach:**\n- **Framework Estimator**: PyTorch (provides modern container environment)\n- **ML Library**: XGBoost (installed via requirements.txt)\n- **Training Script**: Custom `train.py` with full control over training logic\n\n**SDK vs. sagemaker-core:**\nWhat took 50+ lines of TrainingJob configuration becomes just a few lines with the Framework Estimator pattern, while maintaining full flexibility through custom training scripts."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T19:20:00.437692Z",
     "start_time": "2025-10-12T19:20:00.380769Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch Framework Estimator configured\n",
      "Training will use: ml.m5.xlarge\n",
      "Entry point: train.py\n",
      "Output location: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13\n"
     ]
    }
   ],
   "execution_count": 69,
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create PyTorch Framework Estimator with custom XGBoost training script\n",
    "# This uses PyTorch container for modern Python ecosystem while training with XGBoost\n",
    "xgb_estimator = PyTorch(\n",
    "    entry_point='train.py',           # Custom training script\n",
    "    source_dir='src/',                # Directory with train.py and requirements.txt\n",
    "    framework_version='2.6.0',          # PyTorch version (not XGBoost!)\n",
    "    py_version='py312',\n",
    "    role=lab_session.role,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    output_path=lab_session.base_s3_uri,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='pytorch-xgboost-churn',\n",
    "\n",
    "    # XGBoost hyperparameters (passed to train.py as CLI arguments)\n",
    "    # Note: Use hyphens not underscores for CLI arg compatibility\n",
    "    hyperparameters={\n",
    "        'max-depth': 5,\n",
    "        'eta': 0.2,\n",
    "        'gamma': 4,\n",
    "        'min-child-weight': 6,\n",
    "        'subsample': 0.8,\n",
    "        'objective': 'binary:logistic',\n",
    "        'num-round': 100,\n",
    "        'eval-metric': 'auc'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ PyTorch Framework Estimator configured\")\n",
    "print(f\"Training will use: {xgb_estimator.instance_type}\")\n",
    "print(f\"Entry point: {xgb_estimator.entry_point}\")\n",
    "print(f\"Output location: {xgb_estimator.output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T19:27:10.110758Z",
     "start_time": "2025-10-12T19:23:49.947002Z"
    }
   },
   "source": [
    "# Train the model - just one line!\n",
    "# Compare this to the complex TrainingJob.create() in sagemaker-core\n",
    "\n",
    "xgb_estimator.fit({\n",
    "    'train': s3_train_path,\n",
    "    'validation': s3_validation_path\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ Training completed!\")\n",
    "print(f\"Model artifacts: {xgb_estimator.model_data}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-xgboost-churn-2025-10-12-19-23-49-990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-12 19:23:53 Starting - Starting the training job...\n",
      "2025-10-12 19:24:25 Downloading - Downloading input data...\n",
      "2025-10-12 19:24:45 Downloading - Downloading the training image........\u001B[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001B[0m\n",
      "\u001B[34mbash: no job control in this shell\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:09,924 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:09,924 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:09,925 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:09,934 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:09,936 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:11,332 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001B[0m\n",
      "\u001B[34mCollecting xgboost==3.0.5 (from -r requirements.txt (line 1))\u001B[0m\n",
      "\u001B[34mDownloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.1.3)\u001B[0m\n",
      "\u001B[34mCollecting sagemaker-training>=5.1.1 (from -r requirements.txt (line 3))\u001B[0m\n",
      "\u001B[34mDownloading sagemaker_training-5.1.1.tar.gz (59 kB)\u001B[0m\n",
      "\u001B[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59.2/59.2 kB 4.1 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): started\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCollecting sagemaker-inference>=1.10.1 (from -r requirements.txt (line 4))\u001B[0m\n",
      "\u001B[34mDownloading sagemaker_inference-1.10.1.tar.gz (23 kB)\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): started\u001B[0m\n",
      "\u001B[34mPreparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.3.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost==3.0.5->-r requirements.txt (line 1)) (1.26.2)\u001B[0m\n",
      "\u001B[34mCollecting nvidia-nccl-cu12 (from xgboost==3.0.5->-r requirements.txt (line 1))\u001B[0m\n",
      "\u001B[34mDownloading nvidia_nccl_cu12-2.28.3-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost==3.0.5->-r requirements.txt (line 1)) (1.11.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->-r requirements.txt (line 2)) (2.8.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->-r requirements.txt (line 2)) (2023.3.post1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->-r requirements.txt (line 2)) (2023.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.29.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.16.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (23.3.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.3.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: gevent in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (23.9.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: inotify_simple==1.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.2.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: werkzeug>=0.15.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (3.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: paramiko>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (3.3.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: psutil>=5.6.7 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (5.9.5)\u001B[0m\n",
      "\u001B[34mCollecting protobuf>=5.28.1 (from sagemaker-training>=5.1.1->-r requirements.txt (line 3))\u001B[0m\n",
      "\u001B[34mDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: botocore>=1.31.57 in /opt/conda/lib/python3.10/site-packages (from sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.32.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 5)) (1.3.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 5)) (3.2.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: s3transfer<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from boto3->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (0.8.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.31.57->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.26.18)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.10/site-packages (from paramiko>=2.4.2->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (4.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.10/site-packages (from paramiko>=2.4.2->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (41.0.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.10/site-packages (from paramiko>=2.4.2->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.15.5->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (2.1.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: zope.event in /opt/conda/lib/python3.10/site-packages (from gevent->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: zope.interface in /opt/conda/lib/python3.10/site-packages (from gevent->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (6.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: greenlet>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gevent->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (3.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.3->paramiko>=2.4.2->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (1.15.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from zope.event->gevent->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (65.6.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4.2->sagemaker-training>=5.1.1->-r requirements.txt (line 3)) (2.21)\u001B[0m\n",
      "\u001B[34mDownloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\u001B[0m\n",
      "\n",
      "2025-10-12 19:26:01 Training - Training image download completed. Training in progress.\u001B[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 94.9/94.9 MB 31.5 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\u001B[0m\n",
      "\u001B[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 322.0/322.0 kB 50.4 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mDownloading nvidia_nccl_cu12-2.28.3-py3-none-manylinux_2_18_x86_64.whl (295.9 MB)\u001B[0m\n",
      "\u001B[34m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 295.9/295.9 MB 6.6 MB/s eta 0:00:00\u001B[0m\n",
      "\u001B[34mBuilding wheels for collected packages: sagemaker-training, sagemaker-inference\u001B[0m\n",
      "\u001B[34mBuilding wheel for sagemaker-training (setup.py): started\u001B[0m\n",
      "\u001B[34mBuilding wheel for sagemaker-training (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCreated wheel for sagemaker-training: filename=sagemaker_training-5.1.1-cp310-cp310-linux_x86_64.whl size=77846 sha256=7579c45e185f086a3026b4fe4bca2df3d8808b21bdbab4858f23d68fdb001f08\u001B[0m\n",
      "\u001B[34mStored in directory: /root/.cache/pip/wheels/9c/6b/55/862b15ea17bff541e5573d8dda3b64352b3a9b510eb123dcb2\u001B[0m\n",
      "\u001B[34mBuilding wheel for sagemaker-inference (setup.py): started\u001B[0m\n",
      "\u001B[34mBuilding wheel for sagemaker-inference (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCreated wheel for sagemaker-inference: filename=sagemaker_inference-1.10.1-py2.py3-none-any.whl size=29733 sha256=63c574d7eac2f12ddc22b7d94e4745f76c0a9b60469e57e3729a2d06d6cd22ba\u001B[0m\n",
      "\u001B[34mStored in directory: /root/.cache/pip/wheels/4f/d8/2a/300a5f9c1dbc89f931aff8eaba60a81bd5c9b814c9d4a0f2de\u001B[0m\n",
      "\u001B[34mSuccessfully built sagemaker-training sagemaker-inference\u001B[0m\n",
      "\u001B[34mInstalling collected packages: protobuf, nvidia-nccl-cu12, xgboost, sagemaker-training, sagemaker-inference\u001B[0m\n",
      "\u001B[34mAttempting uninstall: protobuf\u001B[0m\n",
      "\u001B[34mFound existing installation: protobuf 3.20.3\u001B[0m\n",
      "\u001B[34mUninstalling protobuf-3.20.3:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled protobuf-3.20.3\u001B[0m\n",
      "\u001B[34mAttempting uninstall: sagemaker-training\u001B[0m\n",
      "\u001B[34mFound existing installation: sagemaker-training 4.7.4\u001B[0m\n",
      "\u001B[34mUninstalling sagemaker-training-4.7.4:\u001B[0m\n",
      "\u001B[34mSuccessfully uninstalled sagemaker-training-4.7.4\u001B[0m\n",
      "\u001B[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001B[0m\n",
      "\u001B[34msagemaker 2.198.0 requires protobuf<5.0,>=3.12, but you have protobuf 6.32.1 which is incompatible.\u001B[0m\n",
      "\u001B[34msmdebug 1.0.34 requires protobuf<=3.20.3,>=3.20.0, but you have protobuf 6.32.1 which is incompatible.\u001B[0m\n",
      "\u001B[34mSuccessfully installed nvidia-nccl-cu12-2.28.3 protobuf-6.32.1 sagemaker-inference-1.10.1 sagemaker-training-5.1.1 xgboost-3.0.5\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m[notice] A new release of pip is available: 23.3.1 -> 25.2\u001B[0m\n",
      "\u001B[34m[notice] To update, run: pip install --upgrade pip\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,212 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,212 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,213 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,214 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,224 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,225 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,235 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,236 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,246 sagemaker-training-toolkit INFO     Invoking user script\u001B[0m\n",
      "\u001B[34mTraining Env:\u001B[0m\n",
      "\u001B[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": 0.2,\n",
      "        \"eval-metric\": \"auc\",\n",
      "        \"gamma\": 4,\n",
      "        \"max-depth\": 5,\n",
      "        \"min-child-weight\": 6,\n",
      "        \"num-round\": 100,\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"subsample\": 0.8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-xgboost-churn-2025-10-12-19-23-49-990\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-136548476532/pytorch-xgboost-churn-2025-10-12-19-23-49-990/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001B[0m\n",
      "\u001B[34m}\u001B[0m\n",
      "\u001B[34mEnvironment variables:\u001B[0m\n",
      "\u001B[34mSM_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_NETWORK_INTERFACE_NAME=eth0\u001B[0m\n",
      "\u001B[34mSM_HPS={\"eta\":0.2,\"eval-metric\":\"auc\",\"gamma\":4,\"max-depth\":5,\"min-child-weight\":6,\"num-round\":100,\"objective\":\"binary:logistic\",\"subsample\":0.8}\u001B[0m\n",
      "\u001B[34mSM_USER_ENTRY_POINT=train.py\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_PARAMS={}\u001B[0m\n",
      "\u001B[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001B[0m\n",
      "\u001B[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001B[0m\n",
      "\u001B[34mSM_CHANNELS=[\"train\",\"validation\"]\u001B[0m\n",
      "\u001B[34mSM_CURRENT_HOST=algo-1\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001B[0m\n",
      "\u001B[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001B[0m\n",
      "\u001B[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001B[0m\n",
      "\u001B[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001B[0m\n",
      "\u001B[34mSM_IS_HETERO=false\u001B[0m\n",
      "\u001B[34mSM_MODULE_NAME=train\u001B[0m\n",
      "\u001B[34mSM_LOG_LEVEL=20\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001B[0m\n",
      "\u001B[34mSM_INPUT_DIR=/opt/ml/input\u001B[0m\n",
      "\u001B[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DIR=/opt/ml/output\u001B[0m\n",
      "\u001B[34mSM_NUM_CPUS=4\u001B[0m\n",
      "\u001B[34mSM_NUM_GPUS=0\u001B[0m\n",
      "\u001B[34mSM_NUM_NEURONS=0\u001B[0m\n",
      "\u001B[34mSM_MODEL_DIR=/opt/ml/model\u001B[0m\n",
      "\u001B[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-136548476532/pytorch-xgboost-churn-2025-10-12-19-23-49-990/source/sourcedir.tar.gz\u001B[0m\n",
      "\u001B[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":0.2,\"eval-metric\":\"auc\",\"gamma\":4,\"max-depth\":5,\"min-child-weight\":6,\"num-round\":100,\"objective\":\"binary:logistic\",\"subsample\":0.8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"pytorch-xgboost-churn-2025-10-12-19-23-49-990\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-136548476532/pytorch-xgboost-churn-2025-10-12-19-23-49-990/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train.py\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--eval-metric\",\"auc\",\"--gamma\",\"4\",\"--max-depth\",\"5\",\"--min-child-weight\",\"6\",\"--num-round\",\"100\",\"--objective\",\"binary:logistic\",\"--subsample\",\"0.8\"]\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001B[0m\n",
      "\u001B[34mSM_HP_ETA=0.2\u001B[0m\n",
      "\u001B[34mSM_HP_EVAL-METRIC=auc\u001B[0m\n",
      "\u001B[34mSM_HP_GAMMA=4\u001B[0m\n",
      "\u001B[34mSM_HP_MAX-DEPTH=5\u001B[0m\n",
      "\u001B[34mSM_HP_MIN-CHILD-WEIGHT=6\u001B[0m\n",
      "\u001B[34mSM_HP_NUM-ROUND=100\u001B[0m\n",
      "\u001B[34mSM_HP_OBJECTIVE=binary:logistic\u001B[0m\n",
      "\u001B[34mSM_HP_SUBSAMPLE=0.8\u001B[0m\n",
      "\u001B[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001B[0m\n",
      "\u001B[34mInvoking script with the following command:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.10 train.py --eta 0.2 --eval-metric auc --gamma 4 --max-depth 5 --min-child-weight 6 --num-round 100 --objective binary:logistic --subsample 0.8\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:29,270 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34mSAGEMAKER ENVIRONMENT\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34m{'additional_framework_parameters': {}, 'channel_input_dirs': {'train': '/opt/ml/input/data/train', 'validation': '/opt/ml/input/data/validation'}, 'current_host': 'algo-1', 'current_instance_group': 'homogeneousCluster', 'current_instance_group_hosts': ['algo-1'], 'current_instance_type': 'ml.m5.xlarge', 'distribution_hosts': [], 'distribution_instance_groups': [], 'framework_module': 'sagemaker_pytorch_container.training:main', 'hosts': ['algo-1'], 'hyperparameters': {'eta': 0.2, 'eval-metric': 'auc', 'gamma': 4, 'max-depth': 5, 'min-child-weight': 6, 'num-round': 100, 'objective': 'binary:logistic', 'subsample': 0.8}, 'input_config_dir': '/opt/ml/input/config', 'input_data_config': {'train': {'TrainingInputMode': 'File', 'S3DistributionType': 'FullyReplicated', 'RecordWrapperType': 'None'}, 'validation': {'TrainingInputMode': 'File', 'S3DistributionType': 'FullyReplicated', 'RecordWrapperType': 'None'}}, 'input_dir': '/opt/ml/input', 'instance_groups': ['homogeneousCluster'], 'instance_groups_dict': {'homogeneousCluster': {'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.xlarge', 'hosts': ['algo-1']}}, 'is_hetero': False, 'is_master': True, 'is_modelparallel_enabled': None, 'is_smddpmprun_installed': False, 'is_smddprun_installed': False, 'job_name': 'pytorch-xgboost-churn-2025-10-12-19-23-49-990', 'log_level': 20, 'master_hostname': 'algo-1', 'model_dir': '/opt/ml/model', 'module_dir': 's3://sagemaker-eu-central-1-136548476532/pytorch-xgboost-churn-2025-10-12-19-23-49-990/source/sourcedir.tar.gz', 'module_name': 'train', 'network_interface_name': 'eth0', 'num_cpus': 4, 'num_gpus': 0, 'num_neurons': 0, 'output_data_dir': '/opt/ml/output/data', 'output_dir': '/opt/ml/output', 'output_intermediate_dir': '/opt/ml/output/intermediate', 'resource_config': {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.xlarge', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.xlarge', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0', 'topology': None}, 'topology': None, 'user_entry_point': 'train.py'}\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34mTRAINING CONFIGURATION\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34mModel directory: /opt/ml/model\u001B[0m\n",
      "\u001B[34mTrain data: /opt/ml/input/data/train\u001B[0m\n",
      "\u001B[34mValidation data: /opt/ml/input/data/validation\u001B[0m\n",
      "\u001B[34mSystem Info:\n",
      "  GPUs: 0, CPUs: 4\n",
      "  Hosts: ['algo-1'], Current: algo-1\u001B[0m\n",
      "\u001B[34mHyperparameters:\n",
      "  max_depth: 5\n",
      "  eta: 0.2\n",
      "  gamma: 4.0\n",
      "  min_child_weight: 6.0\u001B[0m\n",
      "\u001B[34msubsample: 0.8\n",
      "  objective: binary:logistic\n",
      "  num_round: 100\n",
      "  eval_metric: auc\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34müì• Loading data...\u001B[0m\n",
      "\u001B[34mLoading 1 file(s) from /opt/ml/input/data/train\u001B[0m\n",
      "\u001B[34mLoaded /opt/ml/input/data/train/train.csv: (3350, 100)\u001B[0m\n",
      "\u001B[34mTotal samples: 3350, Features: 99\u001B[0m\n",
      "\u001B[34mLoading 1 file(s) from /opt/ml/input/data/validation\u001B[0m\n",
      "\u001B[34mLoaded /opt/ml/input/data/validation/validation.csv: (1105, 100)\u001B[0m\n",
      "\u001B[34mTotal samples: 1105, Features: 99\u001B[0m\n",
      "\u001B[34müî® Creating DMatrix...\u001B[0m\n",
      "\u001B[34müöÄ Starting training...\u001B[0m\n",
      "\u001B[34mTraining for 100 rounds with early stopping\u001B[0m\n",
      "\u001B[34m[0]#011train-auc:0.92526#011validation-auc:0.91339\u001B[0m\n",
      "\u001B[34m[10]#011train-auc:0.97897#011validation-auc:0.97171\u001B[0m\n",
      "\u001B[34m[20]#011train-auc:0.98480#011validation-auc:0.97750\u001B[0m\n",
      "\u001B[34m[30]#011train-auc:0.98535#011validation-auc:0.97796\u001B[0m\n",
      "\u001B[34m[40]#011train-auc:0.98551#011validation-auc:0.97818\u001B[0m\n",
      "\u001B[34m[48]#011train-auc:0.98550#011validation-auc:0.97816\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34mTRAINING COMPLETED\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34mFinal train auc: 0.9855\u001B[0m\n",
      "\u001B[34mFinal validation auc: 0.9782\u001B[0m\n",
      "\u001B[34mBest iteration: 38\u001B[0m\n",
      "\u001B[34mBest score: 0.9782\u001B[0m\n",
      "\u001B[34mvalidation-auc:0.9782\u001B[0m\n",
      "\u001B[34mtrain-auc:0.9855\u001B[0m\n",
      "\u001B[34müíæ Saving model...\u001B[0m\n",
      "\u001B[34m/opt/ml/code/train.py:173: UserWarning: [19:26:30] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  model.save_model(model_path)\u001B[0m\n",
      "\u001B[34m‚úÖ Model saved to /opt/ml/model/xgboost-model\u001B[0m\n",
      "\u001B[34m‚úÖ Metadata saved to /opt/ml/model/metadata.json\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34müéâ TRAINING PIPELINE COMPLETED SUCCESSFULLY\u001B[0m\n",
      "\u001B[34m============================================================\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:30,553 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:30,553 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001B[0m\n",
      "\u001B[34m2025-10-12 19:26:30,553 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001B[0m\n",
      "\n",
      "2025-10-12 19:26:49 Uploading - Uploading generated training model\n",
      "2025-10-12 19:26:49 Completed - Training job completed\n",
      "Training seconds: 145\n",
      "Billable seconds: 145\n",
      "‚úÖ Training completed!\n",
      "Model artifacts: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13/pytorch-xgboost-churn-2025-10-12-19-23-49-990/output/model.tar.gz\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ‚ö° Assignment 3: Hyperparameter Tuning with the SDK\n\nThis section demonstrates automated hyperparameter optimization using the **SageMaker SDK's HyperparameterTuner**.\n\n**What You'll Learn:**\n- Defining hyperparameter search spaces with typed parameters\n- Configuring Bayesian optimization strategy\n- Running parallel tuning jobs with resource management\n- Analyzing tuning results and selecting best models\n\n**SDK vs. sagemaker-core:**\nThe HyperparameterTuner class makes tuning much more intuitive compared to the complex HyperParameterTuningJobConfig shapes from Lab 1."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sagemaker.tuner import (\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    "    ContinuousParameter\n",
    ")\n",
    "\n",
    "# Define hyperparameter ranges - much cleaner than sagemaker-core!\n",
    "# Note: Use hyphens to match CLI argument format in train.py\n",
    "hyperparameter_ranges = {\n",
    "    'max-depth': IntegerParameter(3, 10),\n",
    "    'eta': ContinuousParameter(0.01, 0.3),\n",
    "    'gamma': ContinuousParameter(0, 5),\n",
    "    'min-child-weight': ContinuousParameter(1, 10),\n",
    "    'subsample': ContinuousParameter(0.5, 1.0),\n",
    "    'num-round': IntegerParameter(50, 200)\n",
    "}\n",
    "\n",
    "# Create tuner with metric definitions\n",
    "# IMPORTANT: metric_definitions is required for framework estimators (not built-in algorithms)\n",
    "# since SageMaker doesn't know how to parse metrics from custom training scripts\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    objective_metric_name='validation:auc',\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=[\n",
    "        {'Name': 'validation:auc', 'Regex': 'validation-auc:([0-9\\\\.]+)'},\n",
    "        {'Name': 'train:auc', 'Regex': 'train-auc:([0-9\\\\.]+)'}\n",
    "    ],\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    "    base_tuning_job_name='pytorch-xgboost-tuning'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Hyperparameter tuner configured\")\n",
    "print(f\"Will run {tuner.max_jobs} tuning jobs\")\n",
    "print(f\"Optimizing: {tuner.objective_metric_name}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Start tuning - one line vs complex sagemaker-core setup!\ntuner.fit({\n    'train': s3_train_path,\n    'validation': s3_validation_path\n})\n\nprint(\"‚úÖ Hyperparameter tuning completed!\")\n\n# Get best training job details using HyperparameterTuningJobAnalytics\n# Note: best_training_job() returns a string (job name), not a dictionary\nfrom sagemaker.analytics import HyperparameterTuningJobAnalytics\n\ntuner_analytics = HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.name)\nfull_df = tuner_analytics.dataframe()\n\n# Get best training job (highest validation:auc)\nbest_job_row = full_df.sort_values('FinalObjectiveValue', ascending=False).iloc[0]\n\nprint(f\"\\nBest job: {best_job_row['TrainingJobName']}\")\nprint(f\"Best AUC: {best_job_row['FinalObjectiveValue']:.4f}\")\n\nprint(\"\\nBest hyperparameters:\")\nfor key in hyperparameter_ranges.keys():\n    print(f\"  {key}: {best_job_row[key]}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Model Deployment\n\nNow we'll deploy the model using different strategies: provisioned endpoints, serverless endpoints, and batch transform."
  },
  {
   "cell_type": "markdown",
   "source": "## Create PyTorchModel with Custom Inference Handler\n\nBefore deploying, we create a `PyTorchModel` with our custom `inference.py` handler. This model will be reused for all deployment types (provisioned endpoint, serverless endpoint, and batch transform), ensuring consistent inference behavior.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "final_estimator = tuner.best_estimator() if 'tuner' in locals() else xgb_estimator\n",
    "\n",
    "# Create PyTorchModel with custom inference handler\n",
    "# This will be reused for all deployments (endpoints and batch transform)\n",
    "\n",
    "pytorch_model = xgb_estimator.create_model(source_dir=xgb_estimator.source_dir, entry_point='inference.py')\n",
    "\n",
    "print(\"‚úÖ PyTorchModel created with custom inference handler\")\n",
    "print(f\"Model data: {pytorch_model.model_data}\")\n",
    "print(f\"Entry point: {pytorch_model.entry_point}\")\n",
    "print(f\"Model name: {pytorch_model.name}\")\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T19:53:49.606289Z",
     "start_time": "2025-10-12T19:53:43.868878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-10-10 12:00:08 Starting - Found matching resource for reuse\n",
      "2025-10-10 12:00:08 Downloading - Downloading the training image\n",
      "2025-10-10 12:00:08 Training - Training image download completed. Training in progress.\n",
      "2025-10-10 12:00:08 Uploading - Uploading generated training model\n",
      "2025-10-10 12:00:08 Completed - Resource reused by training job: pytorch-xgboost-tuni-251010-1355-007-5c42678f\n",
      "‚úÖ PyTorchModel created with custom inference handler\n",
      "Model data: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13/pytorch-xgboost-churn-2025-10-12-19-23-49-990/output/model.tar.gz\n",
      "Entry point: inference.py\n",
      "Model name: pytorch-xgboost-churn-2025-10-12-19-53-49-489\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T19:34:01.152718Z",
     "start_time": "2025-10-12T19:34:01.108370Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": "# Deploy the best model from tuning to a provisioned endpoint\n# Uses the PyTorchModel with custom inference.py handler\n\npredictor = pytorch_model.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m5.xlarge',\n    endpoint_name=lab_session.endpoint_name\n)\n\nprint(f\"‚úÖ Model deployed to endpoint: {predictor.endpoint_name}\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T19:56:25.523805Z",
     "start_time": "2025-10-12T19:53:53.073876Z"
    }
   },
   "source": [
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "# Deploy serverless endpoint using the same PyTorchModel\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=2048,\n",
    "    max_concurrency=10,\n",
    ")\n",
    "\n",
    "serverless_predictor = pytorch_model.deploy(\n",
    "    serverless_inference_config=serverless_config,\n",
    "    endpoint_name=lab_session.serverless_endpoint_name\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Serverless model deployed: {serverless_predictor.endpoint_name}\")\n",
    "print(f\"Memory: {serverless_config.memory_size_in_mb}MB\")\n",
    "print(f\"Max concurrency: {serverless_config.max_concurrency}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to CPU type when using serverless inference\n",
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13/pytorch-xgboost-churn-2025-10-12-19-23-49-990/output/model.tar.gz), script artifact (src/), and dependencies ([]) into single tar.gz file located at s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13/pytorch-xgboost-churn-2025-10-12-19-53-49-489/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-xgboost-churn-2025-10-12-19-53-49-489\n",
      "INFO:sagemaker:Creating endpoint-config with name customer-churn-pytorch-serverless-endpoint\n",
      "INFO:sagemaker:Creating endpoint with name customer-churn-pytorch-serverless-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!‚úÖ Serverless model deployed: customer-churn-pytorch-serverless-endpoint\n",
      "Memory: 2048MB\n",
      "Max concurrency: 10\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:31:08.493986Z",
     "start_time": "2025-10-10T12:26:59.227225Z"
    }
   },
   "source": "## Batch Transform\n\nThe SageMaker SDK also simplifies batch inference.\n\n**Key Points:**\n\n1. **Reusing PyTorchModel**: We use the same `PyTorchModel` created earlier that includes our custom `inference.py` handler. This ensures consistent inference behavior across endpoints and batch transform.\n\n2. **Custom Inference Handler**: The `inference.py` script handles XGBoost models in the PyTorch container with four functions:\n   - `model_fn()`: Load the XGBoost model from disk\n   - `input_fn()`: Parse CSV input into XGBoost DMatrix (handles structured arrays)\n   - `predict_fn()`: Run inference with the model\n   - `output_fn()`: Format predictions as CSV output"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create transformer from the PyTorchModel with custom inference handler\n# Uses the same pytorch_model we created earlier with inference.py\n\ntransformer = pytorch_model.transformer(\n    instance_count=1,\n    instance_type='ml.m5.xlarge',\n    output_path=lab_session.transform_output_s3_uri,\n)\n\n# Run batch transform\ntransformer.transform(\n    data=s3_test_path,\n    content_type='text/csv',\n    split_type='Line'\n)\n\nprint(f\"‚úÖ Batch transform completed!\")\nprint(f\"Results saved to: {transformer.output_path}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Inference\n",
    "\n",
    "This is where the SageMaker SDK really shines - compare this clean interface to the fiddly `invoke()` + `read()` + `decode()` + `split()` in sagemaker-core!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T19:57:49.251662Z",
     "start_time": "2025-10-12T19:57:45.288244Z"
    }
   },
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Test both endpoints with clean interface - no more fiddly response parsing!\n",
    "sample_data = test_features.head(10).values\n",
    "\n",
    "# print(\"=== ENDPOINT COMPARISON ===\")\n",
    "# print(f\"Testing with {len(sample_data)} samples\\n\")\n",
    "#\n",
    "# # Provisioned endpoint\n",
    "# print(\"üñ•Ô∏è  PROVISIONED ENDPOINT:\")\n",
    "# start_time = time.time()\n",
    "# provisioned_predictions = predictor.predict(sample_data)  # Clean and simple!\n",
    "# provisioned_latency = (time.time() - start_time) * 1000\n",
    "#\n",
    "# print(f\"   Predictions shape: {np.array(provisioned_predictions).shape}\")\n",
    "# print(f\"   Latency: {provisioned_latency:.1f}ms\")\n",
    "# print(f\"   Sample predictions: {provisioned_predictions[:3]}\")\n",
    "#\n",
    "# print()\n",
    "\n",
    "# Serverless endpoint  \n",
    "print(\"‚òÅÔ∏è  SERVERLESS ENDPOINT:\")\n",
    "start_time = time.time()\n",
    "serverless_predictions = serverless_predictor.predict(sample_data)  # Also clean!\n",
    "serverless_latency = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"   Predictions shape: {np.array(serverless_predictions).shape}\")\n",
    "print(f\"   Latency: {serverless_latency:.1f}ms\")\n",
    "print(f\"   Sample predictions: {serverless_predictions[:3]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Compare results\n",
    "# predictions_match = np.allclose(provisioned_predictions, serverless_predictions, rtol=1e-5)\n",
    "# print(f\"‚úÖ Predictions match: {predictions_match}\")\n",
    "# print(f\"üìä Latency difference: {abs(serverless_latency - provisioned_latency):.1f}ms\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÅÔ∏è  SERVERLESS ENDPOINT:\n",
      "   Predictions shape: (10,)\n",
      "   Latency: 3913.1ms\n",
      "   Sample predictions: [0.51147664 0.11478397 0.73954403]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate on full test set\n",
    "print(\"=== MODEL PERFORMANCE ===\")\n",
    "\n",
    "# Get predictions for full test set\n",
    "test_predictions = predictor.predict(test_features.values)\n",
    "test_probabilities = np.array(test_predictions)\n",
    "test_binary = (test_probabilities >= 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_target, test_binary)\n",
    "precision = precision_score(test_target, test_binary)\n",
    "recall = recall_score(test_target, test_binary)\n",
    "auc = roc_auc_score(test_target, test_probabilities)\n",
    "\n",
    "print(f\"Test Set Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  ROC AUC:   {auc:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Tested on {len(test_target)} samples\")\n",
    "print(f\"üéØ Churn rate in test set: {test_target.mean():.1%}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The SageMaker SDK also makes cleanup simpler with built-in methods."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T19:53:18.673095Z",
     "start_time": "2025-10-12T19:53:16.736521Z"
    }
   },
   "source": [
    "# Clean up resources - comprehensive cleanup including configurations and models\n",
    "\n",
    "print(\"üßπ Cleaning up resources...\")\n",
    "\n",
    "# Import boto3 for comprehensive cleanup\n",
    "import boto3\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=lab_session.region)\n",
    "\n",
    "# Delete endpoints first\n",
    "print(\"\\nüóëÔ∏è  Deleting endpoints...\")\n",
    "try:\n",
    "    predictor.delete_endpoint(delete_endpoint_config=False)  # Don't auto-delete config\n",
    "    print(\"‚úÖ Provisioned endpoint deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not delete provisioned endpoint: {e}\")\n",
    "\n",
    "try:\n",
    "    serverless_predictor.delete_endpoint(delete_endpoint_config=False)  # Don't auto-delete config  \n",
    "    print(\"‚úÖ Serverless endpoint deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not delete serverless endpoint: {e}\")\n",
    "\n",
    "# Now explicitly delete endpoint configurations\n",
    "print(\"\\nüóëÔ∏è  Deleting endpoint configurations...\")\n",
    "try:\n",
    "    # Get the endpoint config name from the predictor\n",
    "    provisioned_config_name = predictor.endpoint_name  # Usually same as endpoint name\n",
    "    sagemaker_client.describe_endpoint_config(EndpointConfigName=provisioned_config_name)\n",
    "    sagemaker_client.delete_endpoint_config(EndpointConfigName=provisioned_config_name)\n",
    "    print(f\"‚úÖ Deleted endpoint config: {provisioned_config_name}\")\n",
    "except sagemaker_client.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ValidationException':\n",
    "        print(f\"‚ÑπÔ∏è  Endpoint config {provisioned_config_name} not found or already deleted\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Could not delete provisioned endpoint config: {e}\")\n",
    "\n",
    "try:\n",
    "    serverless_config_name = serverless_predictor.endpoint_name\n",
    "    sagemaker_client.describe_endpoint_config(EndpointConfigName=serverless_config_name)\n",
    "    sagemaker_client.delete_endpoint_config(EndpointConfigName=serverless_config_name)\n",
    "    print(f\"‚úÖ Deleted endpoint config: {serverless_config_name}\")\n",
    "except sagemaker_client.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ValidationException':\n",
    "        print(f\"‚ÑπÔ∏è  Endpoint config {serverless_config_name} not found or already deleted\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Could not delete serverless endpoint config: {e}\")\n",
    "\n",
    "# Delete models\n",
    "print(\"\\nüóëÔ∏è  Deleting models...\")\n",
    "try:\n",
    "    # Get model names from the endpoint configs (requires describing them first)\n",
    "    # For the provisioned endpoint\n",
    "    try:\n",
    "        response = sagemaker_client.describe_endpoint(EndpointName=predictor.endpoint_name)\n",
    "        config_name = response['EndpointConfigName']\n",
    "        config_response = sagemaker_client.describe_endpoint_config(EndpointConfigName=config_name)\n",
    "        model_name = config_response['ProductionVariants'][0]['ModelName']\n",
    "        sagemaker_client.delete_model(ModelName=model_name)\n",
    "        print(f\"‚úÖ Deleted model: {model_name}\")\n",
    "    except:\n",
    "        pass  # Model might already be deleted\n",
    "    \n",
    "    # For the serverless endpoint\n",
    "    try:\n",
    "        response = sagemaker_client.describe_endpoint(EndpointName=serverless_predictor.endpoint_name)\n",
    "        config_name = response['EndpointConfigName']\n",
    "        config_response = sagemaker_client.describe_endpoint_config(EndpointConfigName=config_name)\n",
    "        model_name = config_response['ProductionVariants'][0]['ModelName']\n",
    "        sagemaker_client.delete_model(ModelName=model_name)\n",
    "        print(f\"‚úÖ Deleted model: {model_name}\")\n",
    "    except:\n",
    "        pass  # Model might already be deleted\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è  Some models may not have been deleted (they might be shared or already deleted)\")\n",
    "\n",
    "# List any remaining resources for verification\n",
    "print(\"\\nüìã Checking for remaining resources...\")\n",
    "try:\n",
    "    # Check for any endpoints with our prefix\n",
    "    remaining_endpoints = sagemaker_client.list_endpoints(\n",
    "        NameContains='customer-churn-pytorch',\n",
    "        MaxResults=10\n",
    "    )\n",
    "    if remaining_endpoints['Endpoints']:\n",
    "        print(f\"‚ö†Ô∏è  Found {len(remaining_endpoints['Endpoints'])} remaining endpoints\")\n",
    "        for ep in remaining_endpoints['Endpoints']:\n",
    "            print(f\"   - {ep['EndpointName']}\")\n",
    "    else:\n",
    "        print(\"‚úÖ No remaining endpoints found\")\n",
    "        \n",
    "    # Check for endpoint configs\n",
    "    remaining_configs = sagemaker_client.list_endpoint_configs(\n",
    "        NameContains='customer-churn-pytorch',\n",
    "        MaxResults=10\n",
    "    )\n",
    "    if remaining_configs['EndpointConfigs']:\n",
    "        print(f\"‚ö†Ô∏è  Found {len(remaining_configs['EndpointConfigs'])} remaining endpoint configs\")\n",
    "        for config in remaining_configs['EndpointConfigs']:\n",
    "            print(f\"   - {config['EndpointConfigName']}\")\n",
    "    else:\n",
    "        print(\"‚úÖ No remaining endpoint configs found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not list remaining resources: {e}\")\n",
    "\n",
    "print(\"\\n‚ú® Cleanup completed!\")\n",
    "print(f\"   Storage location: {lab_session.base_s3_uri}\")\n",
    "print(\"\\nüìù Remember to delete S3 data when you're completely done!\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: customer-churn-pytorch-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning up resources...\n",
      "\n",
      "üóëÔ∏è  Deleting endpoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: customer-churn-pytorch-serverless-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Could not delete provisioned endpoint: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"customer-churn-pytorch-endpoint\".\n",
      "‚úÖ Serverless endpoint deleted\n",
      "\n",
      "üóëÔ∏è  Deleting endpoint configurations...\n",
      "‚ÑπÔ∏è  Endpoint config customer-churn-pytorch-endpoint not found or already deleted\n",
      "‚úÖ Deleted endpoint config: customer-churn-pytorch-serverless-endpoint\n",
      "\n",
      "üóëÔ∏è  Deleting models...\n",
      "\n",
      "üìã Checking for remaining resources...\n",
      "‚úÖ No remaining endpoints found\n",
      "‚úÖ No remaining endpoint configs found\n",
      "\n",
      "‚ú® Cleanup completed!\n",
      "   Storage location: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-12T18-05-13\n",
      "\n",
      "üìù Remember to delete S3 data when you're completely done!\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: SageMaker SDK vs sagemaker-core\n",
    "\n",
    "This notebook demonstrates the dramatic improvements in developer experience when using the SageMaker SDK:\n",
    "\n",
    "### Code Reduction:\n",
    "- **Training**: 50+ lines ‚Üí 10 lines (80% reduction)\n",
    "- **Hyperparameter Tuning**: 40+ lines ‚Üí 15 lines (70% reduction)  \n",
    "- **Deployment**: 30+ lines ‚Üí 5 lines (85% reduction)\n",
    "- **Inference**: Fiddly response parsing ‚Üí Clean `.predict()` calls\n",
    "\n",
    "### Developer Experience:\n",
    "- ‚úÖ **Intuitive**: ML-focused abstractions (Estimators, Predictors)\n",
    "- ‚úÖ **Less error-prone**: Automatic configuration and validation\n",
    "- ‚úÖ **Cleaner inference**: No manual response parsing\n",
    "- ‚úÖ **Better debugging**: Framework-specific error handling\n",
    "- ‚úÖ **Local mode**: Test everything locally before deployment\n",
    "\n",
    "### When to use each:\n",
    "- **SageMaker SDK**: ML development, experimentation, production ML workflows\n",
    "- **sagemaker-core**: Infrastructure management, custom tooling, precise AWS API control\n",
    "\n",
    "### Best of both worlds:\n",
    "Our `CoreLabSession` provides session management while SageMaker SDK handles ML operations - giving you both control and convenience!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
