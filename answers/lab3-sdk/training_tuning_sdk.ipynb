{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker SDK Training & Hyperparameter Tuning\n",
    "\n",
    "**Lab 3 - Assignments 2 & 3 Answer Notebook**\n",
    "\n",
    "This notebook demonstrates model training and hyperparameter tuning using the SageMaker Python SDK, answering:\n",
    "- **Assignment 2**: Training with Framework Estimators\n",
    "- **Assignment 3**: Hyperparameter Tuning with the SDK\n",
    "\n",
    "**Key Benefits of SDK Approach:**\n",
    "- 80% less code compared to sagemaker-core\n",
    "- High-level ML abstractions (Estimators, Tuners, Predictors)\n",
    "- Automatic handling of AWS resource configuration\n",
    "- Clean inference with automatic serialization\n",
    "- Integrated hyperparameter tuning workflow"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T08:46:47.908020Z",
     "start_time": "2025-10-22T08:46:47.786042Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "We'll use our existing `CoreLabSession` for session management but switch to SageMaker SDK for ML operations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T08:47:10.621140Z",
     "start_time": "2025-10-22T08:46:50.047730Z"
    }
   },
   "source": [
    "from corelab.core.session import CoreLabSession\n",
    "\n",
    "# Use our custom session for authentication and S3 management\n",
    "lab_session = CoreLabSession('pytorch', 'customer-churn',\n",
    "                            default_folder='sagemaker_sdk_notebook', \n",
    "                            create_run_folder=True,\n",
    "                             aws_profile='sagemaker-role')\n",
    "lab_session.print()\n",
    "\n",
    "# Get SageMaker session for SDK integration\n",
    "sagemaker_session = lab_session.get_sagemaker_session()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/machiel/Development/crystalline/sagemaker/corelab/.venv/lib/python3.13/site-packages/sagemaker_core/main/shapes.py:6645: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  domain: The machine learning domain of the model and its components. Valid Values: COMPUTER_VISION \\| NATURAL_LANGUAGE_PROCESSING \\| MACHINE_LEARNING\n",
      "/Users/machiel/Development/crystalline/sagemaker/corelab/.venv/lib/python3.13/site-packages/sagemaker_core/main/shapes.py:7450: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  schedule_expression: A cron expression that describes details about the monitoring schedule. The supported cron expressions are:   If you want to set the job to start every hour, use the following:  Hourly: cron(0 \\* ? \\* \\* \\*)    If you want to start the job daily:  cron(0 [00-23] ? \\* \\* \\*)    If you want to run the job one time, immediately, use the following keyword:  NOW    For example, the following are valid cron expressions:   Daily at noon UTC: cron(0 12 ? \\* \\* \\*)    Daily at midnight UTC: cron(0 0 ? \\* \\* \\*)    To support running every 6, 12 hours, the following are also supported:  cron(0 [00-23]/[01-24] ? \\* \\* \\*)  For example, the following are valid cron expressions:   Every 12 hours, starting at 5pm UTC: cron(0 17/12 ? \\* \\* \\*)    Every two hours starting at midnight: cron(0 0/2 ? \\* \\* \\*)       Even though the cron expression is set to start at 5PM UTC, note that there could be a delay of 0-20 minutes from the actual requested time to run the execution.    We recommend that if you would like a daily schedule, you do not provide this parameter. Amazon SageMaker AI will pick a time for running every day.    You can also specify the keyword NOW to run the monitoring job immediately, one time, without recurring.\n",
      "/Users/machiel/Development/crystalline/sagemaker/corelab/.venv/lib/python3.13/site-packages/sagemaker_core/main/shapes.py:9820: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  resource_retained_billable_time_in_seconds: The billable time in seconds used by the warm pool. Billable time refers to the absolute wall-clock time. Multiply ResourceRetainedBillableTimeInSeconds by the number of instances (InstanceCount) in your training cluster to get the total compute time SageMaker bills you if you run warm pool training. The formula is as follows: ResourceRetainedBillableTimeInSeconds \\* InstanceCount.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/machiel/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name machiel-crystalline to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falling back to profile: sagemaker-role\n",
      "AWS region: eu-central-1\n",
      "Execution role arn:aws:iam::136548476532:role/service-role/AmazonSageMaker-ExecutionRole-20250902T164316\n",
      "Output bucket uri: s3://sagemaker-eu-central-1-136548476532/sagemaker_sdk_notebook/2025-10-22T08-47-08\n",
      "Framework: pytorch\n",
      "Project name: customer-churn\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Assignment 2: Training with Framework Estimators\n",
    "\n",
    "This section demonstrates training with the **PyTorch Framework Estimator** with a custom XGBoost training script - the modern, flexible approach (Lab 3 Option A - Recommended).\n",
    "\n",
    "**What You'll Learn:**\n",
    "- Using PyTorch Framework Estimator for custom training logic\n",
    "- Running XGBoost within PyTorch container (modern Python ecosystem)\n",
    "- Creating custom training scripts with SageMaker conventions\n",
    "- Passing hyperparameters as command-line arguments\n",
    "- Automatic dependency installation via requirements.txt\n",
    "\n",
    "**Key Approach:**\n",
    "- **Framework Estimator**: PyTorch (provides modern container environment)\n",
    "- **ML Library**: XGBoost (installed via requirements.txt)\n",
    "- **Training Script**: Custom `train.py` with full control over training logic\n",
    "\n",
    "**SDK vs. sagemaker-core:**\n",
    "What took 50+ lines of TrainingJob configuration becomes just a few lines with the Framework Estimator pattern, while maintaining full flexibility through custom training scripts."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T08:52:31.665917Z",
     "start_time": "2025-10-22T08:52:31.589924Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[38;2;255;0;0m╭─\u001B[0m\u001B[38;2;255;0;0m──────────────────────────────\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[1;38;2;255;0;0mTraceback \u001B[0m\u001B[1;2;38;2;255;0;0m(most recent call last)\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[38;2;255;0;0m───────────────────────────────\u001B[0m\u001B[38;2;255;0;0m─╮\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m in <module>:14                                                                                   \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m11 \u001B[0msklearn = SKLearn(entry_point=\u001B[33m'\u001B[0m\u001B[33mtrain.py\u001B[0m\u001B[33m'\u001B[0m, image_uri=\u001B[33m'\u001B[0m\u001B[33m683313688378.dkr.ecr.us-east-1.amaz\u001B[0m    \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m12 \u001B[0m                                                                                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m13 \u001B[0msklearn.fit({                                                                               \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[31m❱ \u001B[0m14 \u001B[2m│   \u001B[0m\u001B[33m'\u001B[0m\u001B[33mtrain\u001B[0m\u001B[33m'\u001B[0m: \u001B[1;4ms3_train_path\u001B[0m,                                                                 \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m15 \u001B[0m\u001B[2m│   \u001B[0m\u001B[33m'\u001B[0m\u001B[33mvalidation\u001B[0m\u001B[33m'\u001B[0m: s3_validation_path                                                        \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m16 \u001B[0m})                                                                                          \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m17 \u001B[0m                                                                                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mNameError: \u001B[0mname \u001B[38;2;0;135;0m's3_train_path'\u001B[0m is not defined\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:14                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span>sklearn = SKLearn(entry_point=<span style=\"color: #808000; text-decoration-color: #808000\">'train.py'</span>, image_uri=<span style=\"color: #808000; text-decoration-color: #808000\">'683313688378.dkr.ecr.us-east-1.amaz</span>    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span>sklearn.fit({                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">'train'</span>: <span style=\"font-weight: bold; text-decoration: underline\">s3_train_path</span>,                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">'validation'</span>: s3_validation_path                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span>})                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008700; text-decoration-color: #008700\">'s3_train_path'</span> is not defined\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create PyTorch Framework Estimator with custom XGBoost training script\n",
    "# This uses PyTorch container for modern Python ecosystem while training with XGBoost\n",
    "my_estimator = PyTorch(\n",
    "    entry_point='train.py',           # Custom training script\n",
    "    source_dir='src/',                # Directory with train.py and requirements.txt\n",
    "    framework_version='2.6.0',          # PyTorch version (not XGBoost!)\n",
    "    py_version='py312',\n",
    "    role=lab_session.role,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    output_path=lab_session.base_s3_uri,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='pytorch-xgboost-churn',\n",
    "\n",
    "    # XGBoost hyperparameters (passed to train.py as CLI arguments)\n",
    "    # Note: Use hyphens not underscores for CLI arg compatibility\n",
    "    hyperparameters={\n",
    "        'max-depth': 5,\n",
    "        'eta': 0.2,\n",
    "        'gamma': 4,\n",
    "        'min-child-weight': 6,\n",
    "        'subsample': 0.8,\n",
    "        'objective': 'binary:logistic',\n",
    "        'num-round': 100,\n",
    "        'eval-metric': 'auc'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✅ PyTorch Framework Estimator configured\")\n",
    "print(f\"Training will use: {my_estimator.instance_type}\")\n",
    "print(f\"Entry point: {my_estimator.entry_point}\")\n",
    "print(f\"Output location: {my_estimator.output_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T09:09:32.592649Z",
     "start_time": "2025-10-22T09:09:32.536482Z"
    }
   },
   "source": [
    "# Train the model - just one line!\n",
    "# Compare this to the complex TrainingJob.create() in sagemaker-core\n",
    "\n",
    "s3_train_path = \"s3://sagemaker-eu-central-1-136548476532/preprocessing_sdk/2025-10-22T09-00-07/customer-churn-2025-10-22T09-00-07/jobs/customer-churn-pytorch-processing-2025-10-22T09-00-42/validation.csv\"\n",
    "\n",
    "s3_validation_path = \"s3://sagemaker-eu-central-1-136548476532/preprocessing_sdk/2025-10-22T09-00-07/customer-churn-2025-10-22T09-00-07/jobs/customer-churn-pytorch-processing-2025-10-22T09-00-42/validation.csv\"\n",
    "\n",
    "s3_test_path = \"s3://sagemaker-eu-central-1-136548476532/preprocessing_sdk/2025-10-22T09-00-07/customer-churn-2025-10-22T09-00-07/jobs/customer-churn-pytorch-processing-2025-10-22T09-00-42/validation.csv\"\n",
    "\n",
    "\n",
    "my_estimator.fit({\n",
    "    'train': s3_train_path,\n",
    "    'validation': s3_validation_path\n",
    "})\n",
    "\n",
    "print(f\"✅ Training completed!\")\n",
    "print(f\"Model artifacts: {my_estimator.model_data}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[38;2;255;0;0m╭─\u001B[0m\u001B[38;2;255;0;0m──────────────────────────────\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[1;38;2;255;0;0mTraceback \u001B[0m\u001B[1;2;38;2;255;0;0m(most recent call last)\u001B[0m\u001B[38;2;255;0;0m \u001B[0m\u001B[38;2;255;0;0m───────────────────────────────\u001B[0m\u001B[38;2;255;0;0m─╮\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m in <module>:11                                                                                   \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m                                                                                                  \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 8 \u001B[0ms3_test_path = \u001B[33m\"\u001B[0m\u001B[33ms3://sagemaker-eu-central-1-136548476532/preprocessing_sdk/2025-10-22T09\u001B[0m    \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m 9 \u001B[0m                                                                                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m10 \u001B[0m                                                                                            \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m \u001B[31m❱ \u001B[0m11 \u001B[1;4mmy_estimator\u001B[0m.fit({                                                                          \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m12 \u001B[0m\u001B[2m│   \u001B[0m\u001B[33m'\u001B[0m\u001B[33mtrain\u001B[0m\u001B[33m'\u001B[0m: s3_train_path,                                                                 \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m13 \u001B[0m\u001B[2m│   \u001B[0m\u001B[33m'\u001B[0m\u001B[33mvalidation\u001B[0m\u001B[33m'\u001B[0m: s3_validation_path                                                        \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m│\u001B[0m   \u001B[2m14 \u001B[0m})                                                                                          \u001B[38;2;255;0;0m│\u001B[0m\n",
       "\u001B[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mNameError: \u001B[0mname \u001B[38;2;0;135;0m'my_estimator'\u001B[0m is not defined\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:11                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>s3_test_path = <span style=\"color: #808000; text-decoration-color: #808000\">\"s3://sagemaker-eu-central-1-136548476532/preprocessing_sdk/2025-10-22T09</span>    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>11 <span style=\"font-weight: bold; text-decoration: underline\">my_estimator</span>.fit({                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">'train'</span>: s3_train_path,                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">'validation'</span>: s3_validation_path                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>})                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008700; text-decoration-color: #008700\">'my_estimator'</span> is not defined\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Assignment 3: Hyperparameter Tuning with the SDK\n",
    "\n",
    "This section demonstrates automated hyperparameter optimization using the **SageMaker SDK's HyperparameterTuner**.\n",
    "\n",
    "**What You'll Learn:**\n",
    "- Defining hyperparameter search spaces with typed parameters\n",
    "- Configuring Bayesian optimization strategy\n",
    "- Running parallel tuning jobs with resource management\n",
    "- Analyzing tuning results and selecting best models\n",
    "\n",
    "**SDK vs. sagemaker-core:**\n",
    "The HyperparameterTuner class makes tuning much more intuitive compared to the complex HyperParameterTuningJobConfig shapes from Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sagemaker.tuner import (\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    "    ContinuousParameter\n",
    ")\n",
    "\n",
    "# Define hyperparameter ranges - much cleaner than sagemaker-core!\n",
    "# Note: Use hyphens to match CLI argument format in train.py\n",
    "hyperparameter_ranges = {\n",
    "    'max-depth': IntegerParameter(3, 10),\n",
    "    'eta': ContinuousParameter(0.01, 0.3),\n",
    "    'gamma': ContinuousParameter(0, 5),\n",
    "    'min-child-weight': ContinuousParameter(1, 10),\n",
    "    'subsample': ContinuousParameter(0.5, 1.0),\n",
    "    'num-round': IntegerParameter(50, 200)\n",
    "}\n",
    "\n",
    "# Create tuner with metric definitions\n",
    "# IMPORTANT: metric_definitions is required for framework estimators (not built-in algorithms)\n",
    "# since SageMaker doesn't know how to parse metrics from custom training scripts\n",
    "tuner = HyperparameterTuner(\n",
    "    my_estimator,\n",
    "    objective_metric_name='validation:auc',\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=[\n",
    "        {'Name': 'validation:auc', 'Regex': 'validation-auc:([0-9\\\\.]+)'},\n",
    "        {'Name': 'train:auc', 'Regex': 'train-auc:([0-9\\\\.]+)'}\n",
    "    ],\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    "    base_tuning_job_name='pytorch-xgboost-tuning'\n",
    ")\n",
    "\n",
    "print(\"✅ Hyperparameter tuner configured\")\n",
    "print(f\"Will run {tuner.max_jobs} tuning jobs\")\n",
    "print(f\"Optimizing: {tuner.objective_metric_name}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Start tuning - one line vs complex sagemaker-core setup!\n",
    "tuner.fit({\n",
    "    'train': s3_train_path,\n",
    "    'validation': s3_validation_path\n",
    "})\n",
    "\n",
    "print(\"✅ Hyperparameter tuning completed!\")\n",
    "\n",
    "# Get best training job details using HyperparameterTuningJobAnalytics\n",
    "# Note: best_training_job() returns a string (job name), not a dictionary\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.name)\n",
    "full_df = tuner_analytics.dataframe()\n",
    "\n",
    "# Get best training job (highest validation:auc)\n",
    "best_job_row = full_df.sort_values('FinalObjectiveValue', ascending=False).iloc[0]\n",
    "\n",
    "print(f\"\\nBest job: {best_job_row['TrainingJobName']}\")\n",
    "print(f\"Best AUC: {best_job_row['FinalObjectiveValue']:.4f}\")\n",
    "\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for key in hyperparameter_ranges.keys():\n",
    "    print(f\"  {key}: {best_job_row[key]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Now we'll deploy the model using different strategies: provisioned endpoints, serverless endpoints, and batch transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PyTorchModel with Custom Inference Handler\n",
    "\n",
    "Before deploying, we create a `PyTorchModel` with our custom `inference.py` handler. This model will be reused for all deployment types (provisioned endpoint, serverless endpoint, and batch transform), ensuring consistent inference behavior."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "final_estimator = tuner.best_estimator() if 'tuner' in locals() else my_estimator\n",
    "\n",
    "# Create PyTorchModel with custom inference handler\n",
    "# This will be reused for all deployments (endpoints and batch transform)\n",
    "\n",
    "churn_model = final_estimator.create_model(source_dir=final_estimator.source_dir, entry_point='inference.py')\n",
    "\n",
    "print(\"✅ Churn model created with custom inference handler\")\n",
    "print(f\"Model data: {churn_model.model_data}\")\n",
    "print(f\"Entry point: {churn_model.entry_point}\")\n",
    "print(f\"Model name: {churn_model.name}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sagemaker import Predictor\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "# Clean up previous endpoint!\n",
    "try:\n",
    "    p = Predictor(endpoint_name=lab_session.serverless_endpoint_name)\n",
    "    p.delete_endpoint()\n",
    "    print(\"Removed previous endpoint (config)\")\n",
    "except Exception as e:\n",
    "    print(\"No previous endpoint found (\", e, \")\")\n",
    "    pass\n",
    "\n",
    "# Deploy serverless endpoint using the same PyTorchModel\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=2048,\n",
    "    max_concurrency=5,\n",
    ")\n",
    "\n",
    "serverless_predictor = churn_model.deploy(\n",
    "    serverless_inference_config=serverless_config,\n",
    "    endpoint_name=lab_session.serverless_endpoint_name,\n",
    ")\n",
    "\n",
    "print(f\"✅ Serverless model deployed: {serverless_predictor.endpoint_name}\")\n",
    "print(f\"Memory: {serverless_config.memory_size_in_mb}MB\")\n",
    "print(f\"Max concurrency: {serverless_config.max_concurrency}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform\n",
    "\n",
    "The SageMaker SDK also simplifies batch inference.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "1. **Reusing PyTorchModel**: We use the same `PyTorchModel` created earlier that includes our custom `inference.py` handler. This ensures consistent inference behavior across endpoints and batch transform.\n",
    "\n",
    "2. **Custom Inference Handler**: The `inference.py` script handles XGBoost models in the PyTorch container with four functions:\n",
    "   - `model_fn()`: Load the XGBoost model from disk\n",
    "   - `input_fn()`: Parse CSV input into XGBoost DMatrix (handles structured arrays)\n",
    "   - `predict_fn()`: Run inference with the model\n",
    "   - `output_fn()`: Format predictions as CSV output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create transformer from the PyTorchModel with custom inference handler\n",
    "# Uses the same pytorch_model we created earlier with inference.py\n",
    "\n",
    "transformer = churn_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=lab_session.transform_output_s3_uri,\n",
    ")\n",
    "\n",
    "# Run batch transform\n",
    "transformer.transform(\n",
    "    data=s3_test_path,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line'\n",
    ")\n",
    "\n",
    "print(f\"✅ Batch transform completed!\")\n",
    "print(f\"Results saved to: {transformer.output_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Inference\n",
    "\n",
    "This is where the SageMaker SDK really shines - compare this clean interface to the fiddly `invoke()` + `read()` + `decode()` + `split()` in sagemaker-core!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from io import StringIO\n",
    "from sagemaker.s3 import S3Downloader\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "test_features = pd.read_csv(StringIO(S3Downloader.read_file(s3_test_path + \"test.csv\")))\n",
    "# pd.read_csv(s3_train_path)\n",
    "# Test both endpoints with clean interface - no more fiddly response parsing!\n",
    "sample_data = test_features.head(10).values\n",
    "\n",
    "# Serverless endpoint  \n",
    "print(\"☁️  SERVERLESS ENDPOINT:\")\n",
    "start_time = time.time()\n",
    "serverless_predictions = serverless_predictor.predict(sample_data)  # Also clean!\n",
    "serverless_latency = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"   Predictions shape: {np.array(serverless_predictions).shape}\")\n",
    "print(f\"   Latency: {serverless_latency:.1f}ms\")\n",
    "print(f\"   Sample predictions: {serverless_predictions[:4]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Compare results\n",
    "# predictions_match = np.allclose(provisioned_predictions, serverless_predictions, rtol=1e-5)\n",
    "# print(f\"✅ Predictions match: {predictions_match}\")\n",
    "# print(f\"📊 Latency difference: {abs(serverless_latency - provisioned_latency):.1f}ms\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The SageMaker SDK also makes cleanup simpler with built-in methods."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Clean up resources - comprehensive cleanup including configurations and models\n",
    "\n",
    "print(\"🧹 Cleaning up resources...\")\n",
    "\n",
    "# Import boto3 for comprehensive cleanup\n",
    "\n",
    "try:\n",
    "    serverless_predictor.delete_endpoint()\n",
    "    print(\"✅ Serverless endpoint deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Could not delete serverless endpoint: {e}\")\n",
    "\n",
    "try:\n",
    "    churn_model.delete_model()\n",
    "    print(\"Model deleted\")\n",
    "except Exception as e:\n",
    "    print(\"Could not delete churn model: {e}\")\n",
    "\n",
    "sagemaker_client = sagemaker_session.sagemaker_client\n",
    "\n",
    "# List any remaining resources for verification\n",
    "print(\"\\n📋 Checking for remaining resources...\")\n",
    "try:\n",
    "    # Check for any endpoints with our prefix\n",
    "    remaining_endpoints = sagemaker_client.list_endpoints(\n",
    "        NameContains='customer-churn-pytorch',\n",
    "        MaxResults=10\n",
    "    )\n",
    "    if remaining_endpoints['Endpoints']:\n",
    "        print(f\"⚠️  Found {len(remaining_endpoints['Endpoints'])} remaining endpoints\")\n",
    "        for ep in remaining_endpoints['Endpoints']:\n",
    "            print(f\"   - {ep['EndpointName']}\")\n",
    "    else:\n",
    "        print(\"✅ No remaining endpoints found\")\n",
    "        \n",
    "    # Check for endpoint configs\n",
    "    remaining_configs = sagemaker_client.list_endpoint_configs(\n",
    "        NameContains='customer-churn-pytorch',\n",
    "        MaxResults=10\n",
    "    )\n",
    "    if remaining_configs['EndpointConfigs']:\n",
    "        print(f\"⚠️  Found {len(remaining_configs['EndpointConfigs'])} remaining endpoint configs\")\n",
    "        for config in remaining_configs['EndpointConfigs']:\n",
    "            print(f\"   - {config['EndpointConfigName']}\")\n",
    "    else:\n",
    "        print(\"✅ No remaining endpoint configs found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not list remaining resources: {e}\")\n",
    "\n",
    "print(\"\\n✨ Cleanup completed!\")\n",
    "print(f\"   Storage location: {lab_session.base_s3_uri}\")\n",
    "print(\"\\n📝 Remember to delete S3 data when you're completely done!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: SageMaker SDK vs sagemaker-core\n",
    "\n",
    "This notebook demonstrates the dramatic improvements in developer experience when using the SageMaker SDK:\n",
    "\n",
    "### Code Reduction:\n",
    "- **Training**: 50+ lines → 10 lines (80% reduction)\n",
    "- **Hyperparameter Tuning**: 40+ lines → 15 lines (70% reduction)  \n",
    "- **Deployment**: 30+ lines → 5 lines (85% reduction)\n",
    "- **Inference**: Fiddly response parsing → Clean `.predict()` calls\n",
    "\n",
    "### Developer Experience:\n",
    "- ✅ **Intuitive**: ML-focused abstractions (Estimators, Predictors)\n",
    "- ✅ **Less error-prone**: Automatic configuration and validation\n",
    "- ✅ **Cleaner inference**: No manual response parsing\n",
    "- ✅ **Better debugging**: Framework-specific error handling\n",
    "- ✅ **Local mode**: Test everything locally before deployment\n",
    "\n",
    "### When to use each:\n",
    "- **SageMaker SDK**: ML development, experimentation, production ML workflows\n",
    "- **sagemaker-core**: Infrastructure management, custom tooling, precise AWS API control\n",
    "\n",
    "### Best of both worlds:\n",
    "Our `CoreLabSession` provides session management while SageMaker SDK handles ML operations - giving you both control and convenience!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
