{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# SageMaker Core Pipeline - Data Prep, Training, and Model Creation\n",
    "\n",
    "This notebook demonstrates how to create a complete ML pipeline using SageMaker Core that includes:\n",
    "1. Data Processing - Prepare and split the customer churn dataset\n",
    "2. Model Training - Train an XGBoost model on processed data\n",
    "3. Model Evaluation - Evaluate the trained model on holdout data\n",
    "4. Model Creation - Create a deployable SageMaker model from training artifacts"
   ]
  },
  {
   "cell_type": "code",
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:17.639149Z",
     "start_time": "2025-10-17T14:06:17.488692Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Initialize CoreLab Session"
   ]
  },
  {
   "cell_type": "code",
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:25.592394Z",
     "start_time": "2025-10-17T14:06:17.645841Z"
    }
   },
   "source": [
    "from corelab.core.session import CoreLabSession\n",
    "\n",
    "lab_session = CoreLabSession(\n",
    "    'xgboost',\n",
    "    'customer-churn-pipeline',\n",
    "    default_folder='pipeline_notebook',\n",
    "    create_run_folder=True,\n",
    "    aws_profile='sagemaker-role'\n",
    ")\n",
    "lab_session.print()\n",
    "core_session = lab_session.core_session"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/machiel/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name machiel-crystalline to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falling back to profile: sagemaker-role\n",
      "AWS region: eu-central-1\n",
      "Execution role arn:aws:iam::136548476532:role/service-role/AmazonSageMaker-ExecutionRole-20250902T164316\n",
      "Output bucket uri: s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22\n",
      "Framework: xgboost\n",
      "Project name: customer-churn-pipeline\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Import SageMaker Pipeline Components\n",
    "\n",
    "Note: SageMaker Pipelines SDK (not sagemaker-core) is used for pipeline orchestration."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:25.908706Z",
     "start_time": "2025-10-17T14:06:25.659422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pipeline-specific imports from SageMaker SDK\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CacheConfig\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterFloat,\n",
    "    ParameterString\n",
    ")\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "# Processing imports - using XGBoostProcessor for better framework integration\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "\n",
    "# Training imports  \n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# Model imports\n",
    "from sagemaker.model import Model\n",
    "\n",
    "print(\"All pipeline modules imported successfully\")"
   ],
   "id": "1cb9485105669aac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pipeline modules imported successfully\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:26.134101Z",
     "start_time": "2025-10-17T14:06:25.957696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create PipelineSession for proper pipeline execution context\n",
    "pipeline_session = PipelineSession(\n",
    "    boto_session=lab_session.core_session.boto_session,\n",
    "    default_bucket=lab_session.core_session.default_bucket(),\n",
    "    default_bucket_prefix=lab_session.core_session.default_bucket_prefix\n",
    ")\n",
    "\n",
    "print(f\"üì¶ Default bucket: {pipeline_session.default_bucket()}\")\n",
    "print(f\"üìÅ Bucket prefix: {pipeline_session.default_bucket_prefix}\")"
   ],
   "id": "4a2671b07ad7fd0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Default bucket: sagemaker-eu-central-1-136548476532\n",
      "üìÅ Bucket prefix: pipeline_notebook/2025-10-17T14-06-22\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Define input and output locations"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:26.176109Z",
     "start_time": "2025-10-17T14:06:26.141144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define data locations\n",
    "data_s3_uri = f\"s3://sagemaker-example-files-prod-{lab_session.region}/datasets/tabular/synthetic/churn.txt\"\n",
    "pipeline_output_s3_uri = lab_session.pipeline_output_s3_uri\n",
    "\n",
    "print(f\"üìÅ Data S3 URI: {data_s3_uri}\")\n",
    "print(f\"üì§ Pipeline Output S3 URI: {pipeline_output_s3_uri}\")"
   ],
   "id": "85dc12da58e401e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data S3 URI: s3://sagemaker-example-files-prod-eu-central-1/datasets/tabular/synthetic/churn.txt\n",
      "üì§ Pipeline Output S3 URI: s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/pipeline_output\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Define Pipeline Parameters\n",
    "\n",
    "Pipeline parameters allow us to customize pipeline executions without modifying the code."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:26.239373Z",
     "start_time": "2025-10-17T14:06:26.205087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define pipeline parameters for flexibility\n",
    "\n",
    "# Processing parameters\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "train_test_split = ParameterFloat(\n",
    "    name=\"TrainTestSplit\",\n",
    "    default_value=0.33\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "max_depth = ParameterString(\n",
    "    name=\"MaxDepth\",\n",
    "    default_value=\"5\"\n",
    ")\n",
    "\n",
    "num_round = ParameterString(\n",
    "    name=\"NumRound\",\n",
    "    default_value=\"100\"\n",
    ")\n",
    "\n",
    "print(\"Pipeline parameters defined\")"
   ],
   "id": "34dcbe2c23a359ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline parameters defined\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:06:51.778343Z",
     "start_time": "2025-10-17T14:06:51.743593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure step caching for faster pipeline iterations\n",
    "# Cache expires after 7 days - adjust based on your needs\n",
    "cache_config = CacheConfig(\n",
    "    enable_caching=True,\n",
    "    expire_after=\"PT1H\"  # ISO 8601 duration format: P7D = 7 days\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Cache configuration created (1-hour TTL)\")\n",
    "print(\"   Steps will reuse cached results when inputs haven't changed\")"
   ],
   "id": "ea69500279181ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cache configuration created (1-hour TTL)\n",
      "   Steps will reuse cached results when inputs haven't changed\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Configure Step Caching\n",
    "\n",
    "Step caching allows SageMaker Pipelines to reuse results from previous executions when inputs haven't changed, significantly speeding up development iterations and reducing costs.\n",
    "\n",
    "**How it works:**\n",
    "- Cache key includes: step inputs, code hash, container image, instance type, and hyperparameters\n",
    "- **Cache hit**: If all match a previous execution within TTL ‚Üí Skip step, reuse outputs\n",
    "- **Cache miss**: If anything differs ‚Üí Re-run step\n",
    "\n",
    "**Benefits:**\n",
    "- ‚ö° Faster pipeline iterations during development\n",
    "- üí∞ Cost savings by skipping expensive training/processing\n",
    "- üêõ Useful for debugging downstream steps without re-running upstream"
   ],
   "id": "ca5232305a8a631f"
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Step 1: Define Processing Step\n",
    "\n",
    "This step processes raw data and splits it into train, validation, and test sets."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:07:00.607864Z",
     "start_time": "2025-10-17T14:07:00.525052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.pytorch import PyTorchProcessor\n",
    "from pathlib import Path\n",
    "import os\n",
    "# Create XGBoostProcessor - framework-aware with better dependency handling\n",
    "xgb_processor = PyTorchProcessor(\n",
    "    framework_version='2.6.0',\n",
    "    py_version='py312',\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    role=lab_session.role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    env={\"PYTHONUNBUFFERED\": \"1\"},\n",
    "    base_job_name='churn-preprocessing'\n",
    ")\n",
    "\n",
    "src_dir = Path(os.getcwd(), '..', 'pipeline', 'src').resolve()\n",
    "print(src_dir, src_dir.exists())\n",
    "# Use step_args pattern for proper pipeline integration\n",
    "processor_args = xgb_processor.run(\n",
    "    code=\"preprocessing.py\",\n",
    "    source_dir=str(src_dir) + '/',  # Directory with code and requirements.txt\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=data_s3_uri,\n",
    "            destination=\"/opt/ml/processing/input/data\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            # destination=f\"{pipeline_output_s3_uri}/data/train\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\", \n",
    "            source=\"/opt/ml/processing/output/validation\",\n",
    "            # destination=f\"{pipeline_output_s3_uri}/data/validation\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            # destination=f\"{pipeline_output_s3_uri}/data/test\"\n",
    "        )\n",
    "    ],\n",
    "    arguments=[\"--train-test-split\", train_test_split.to_string()]\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessCustomerChurnData\",\n",
    "    step_args=processor_args,\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Processing step defined with caching enabled\")"
   ],
   "id": "2dd92c1e7b7691b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline/src True\n",
      "‚úÖ Processing step defined with caching enabled\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Step 2: Define Training Step\n",
    "\n",
    "This step trains an XGBoost model using the processed data from Step 1."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:07:02.040008Z",
     "start_time": "2025-10-17T14:07:01.757078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create estimator using Pytorch image and our own entry-point\n",
    "my_estimator = PyTorch(\n",
    "    framework_version='2.6.0',\n",
    "    py_version='py312',\n",
    "    entry_point='train.py',\n",
    "    source_dir=str(src_dir) + '/',\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=lab_session.role,\n",
    "    output_path=f\"{pipeline_output_s3_uri}/models\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    hyperparameters={\n",
    "        \"max_depth\": max_depth,\n",
    "        \"eta\": \"0.2\",\n",
    "        \"gamma\": \"4\",\n",
    "        \"min_child_weight\": \"6\",\n",
    "        \"subsample\": \"0.8\",\n",
    "        \"verbosity\": \"0\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": num_round\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use step_args pattern for training step\n",
    "training_args = my_estimator.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainXGBoostModel\",\n",
    "    step_args=training_args,\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training step defined with caching enabled\")"
   ],
   "id": "179ab1cb1d1c43ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training step defined with caching enabled\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Step 3: Define Evaluation Step\n",
    "\n",
    "This step evaluates the trained model against the validation dataset created during preprocessing.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:07:03.982153Z",
     "start_time": "2025-10-17T14:07:03.879453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create ScriptProcessor for evaluation to run custom metrics\n",
    "evaluation_src_dir = Path(os.getcwd(), 'src').resolve()\n",
    "script_processor = PyTorchProcessor(\n",
    "    framework_version='2.6.0',\n",
    "    py_version='py312',\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    role=lab_session.role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    base_job_name='churn-evaluation',\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    env={'PYTHONUNBUFFERED': '1'}\n",
    ")\n",
    "\n",
    "evaluation_args = script_processor.run(\n",
    "    code='evaluate.py',\n",
    "    source_dir=str(evaluation_src_dir) + '/',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/model'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/evaluation'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation',\n",
    "            source='/opt/ml/processing/output'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json'\n",
    ")\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name='EvaluateModel',\n",
    "    step_args=evaluation_args,\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "print('‚úÖ Evaluation step defined with caching enabled')\n"
   ],
   "id": "875edd3dd452de5e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation step defined with caching enabled\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Step 4: Define Model Creation Step\n",
    "\n",
    "This step creates a SageMaker Model from the trained model artifacts."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:07:08.021578Z",
     "start_time": "2025-10-17T14:07:07.952516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a Model object using pipeline session for consistency\n",
    "model = PyTorchModel(\n",
    "    framework_version='2.6.0',\n",
    "    py_version='py312',\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    role=lab_session.role,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "# Use step_args pattern for model creation\n",
    "model_create_args = model.create(instance_type='ml.m5.large')\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"CreateXGBoostModel\",\n",
    "    step_args=model_create_args\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model creation step defined\")"
   ],
   "id": "764d8de3f1ee3be2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model creation step defined\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Optional: Model Registry Step\n",
    "\n",
    "Register the model in SageMaker Model Registry for versioning and deployment management."
   ]
  },
  {
   "cell_type": "code",
   "id": "20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:15:08.986317Z",
     "start_time": "2025-10-17T14:15:08.918876Z"
    }
   },
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "  model_statistics=MetricsSource(\n",
    "      s3_uri=Join(on=\"/\", values=[\n",
    "          step_evaluate.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "          \"evaluation.json\"\n",
    "      ]),\n",
    "      content_type=\"application/json\"\n",
    "  )\n",
    ")\n",
    "\n",
    "register_args = model.register(content_types=[\"text/csv\"], response_types=[\"text/csv\"],\n",
    "                          inference_instances=[\"ml.m5.large\", \"ml.m5.xlarge\"], transform_instances=[\"ml.m5.large\"],\n",
    "                          model_package_group_name=\"customer-churn-models\", approval_status=\"Approved\",\n",
    "                               model_metrics=model_metrics,\n",
    "                          description=\"XGBoost model for customer churn prediction\")\n",
    "step_register_model = ModelStep(\n",
    "    name=\"RegisterXGBoostModel\",\n",
    "    step_args=register_args\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model registration step defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model registration step defined\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Create and Execute the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "id": "22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:15:11.764616Z",
     "start_time": "2025-10-17T14:15:11.719952Z"
    }
   },
   "source": [
    "# Create the pipeline with fixed name for versioning\n",
    "# SageMaker Pipelines now support versioning - use fixed names instead of timestamps\n",
    "pipeline_name = \"customer-churn-pipeline\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        train_test_split,\n",
    "        training_instance_type,\n",
    "        max_depth,\n",
    "        num_round\n",
    "    ],\n",
    "    steps=[\n",
    "        step_process,\n",
    "        step_train,\n",
    "        step_evaluate,\n",
    "        step_create_model,\n",
    "        step_register_model\n",
    "    ],\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Pipeline Name: {pipeline_name}\")\n",
    "print(f\"üìä Pipeline Steps: {len(pipeline.steps)}\")\n",
    "print(\"‚ÑπÔ∏è  Using fixed name - SageMaker will create versions automatically\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Pipeline Name: customer-churn-pipeline\n",
      "üìä Pipeline Steps: 5\n",
      "‚ÑπÔ∏è  Using fixed name - SageMaker will create versions automatically\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Validate Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "id": "24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:15:14.189845Z",
     "start_time": "2025-10-17T14:15:13.598970Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "print('cwd', os.getcwd())\n",
    "# Validate the pipeline definition\n",
    "pipeline_definition = json.loads(pipeline.definition())\n",
    "print(\"Pipeline definition validated successfully!\")\n",
    "print(f\"\\nPipeline has {len(pipeline_definition['Steps'])} steps:\")\n",
    "for step in pipeline_definition['Steps']:\n",
    "    print(f\"  - {step['Name']}: {step['Type']}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded /Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline/src/ to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/978d17ddb834625a9405da834163bb80a58184dc5cfd4c7f8e3d580d4cb90efb/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd /Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/688eae6b48c95bd4e87bf60c57d4a119c4b00fe04a0b3e00a5c0202befc915c6/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded /Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline/src/ to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/ef18a88a2f6a11c841028de041f757ce2d9b757c9ba89046536ba64d72fbc7d1/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/1de680f13a58371bcae623a94882c9316259bd6263be2afff8e006c05ffceeed/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline definition validated successfully!\n",
      "\n",
      "Pipeline has 5 steps:\n",
      "  - PreprocessCustomerChurnData: Processing\n",
      "  - TrainXGBoostModel: Training\n",
      "  - EvaluateModel: Processing\n",
      "  - CreateXGBoostModel-CreateModel: Model\n",
      "  - RegisterXGBoostModel-RegisterModel: RegisterModel\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Create/Update and Execute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "id": "26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T14:15:20.586564Z",
     "start_time": "2025-10-17T14:15:16.724570Z"
    }
   },
   "source": [
    "# Create/update the pipeline (creates new version if pipeline exists)\n",
    "response = pipeline.upsert(role_arn=lab_session.role)\n",
    "print(f\"‚úÖ Pipeline '{pipeline_name}' created/updated successfully\")\n",
    "\n",
    "# Check if this created a new version\n",
    "try:\n",
    "    versions = pipeline.list_pipeline_versions()\n",
    "    version_count = len(versions)\n",
    "    latest_version = versions[0]['PipelineVersion'] if versions else 1\n",
    "    print(f\"üìã Pipeline now has {version_count} version(s), latest: v{latest_version}\")\n",
    "except:\n",
    "    print(\"üìã Version information not available\")\n",
    "\n",
    "# Start pipeline execution\n",
    "execution = pipeline.start(\n",
    "    parameters={\n",
    "        \"ProcessingInstanceType\": \"ml.m5.large\",\n",
    "        \"TrainingInstanceType\": \"ml.m5.large\", \n",
    "        \"TrainTestSplit\": 0.33,\n",
    "        \"MaxDepth\": \"5\",\n",
    "        \"NumRound\": \"100\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"üöÄ Pipeline execution started\")\n",
    "print(f\"üìù Execution ARN: {execution.arn}\")\n",
    "print(f\"üìä Status: {execution.describe()['PipelineExecutionStatus']}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded /Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline/src/ to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/978d17ddb834625a9405da834163bb80a58184dc5cfd4c7f8e3d580d4cb90efb/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/688eae6b48c95bd4e87bf60c57d4a119c4b00fe04a0b3e00a5c0202befc915c6/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded /Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline/src/ to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/ef18a88a2f6a11c841028de041f757ce2d9b757c9ba89046536ba64d72fbc7d1/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/1de680f13a58371bcae623a94882c9316259bd6263be2afff8e006c05ffceeed/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded /Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline/src/ to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/978d17ddb834625a9405da834163bb80a58184dc5cfd4c7f8e3d580d4cb90efb/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/688eae6b48c95bd4e87bf60c57d4a119c4b00fe04a0b3e00a5c0202befc915c6/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded /Users/machiel/Development/crystalline/sagemaker/corelab/answers/pipeline/src/ to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/ef18a88a2f6a11c841028de041f757ce2d9b757c9ba89046536ba64d72fbc7d1/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-10-17T14-06-22/customer-churn-pipeline/code/1de680f13a58371bcae623a94882c9316259bd6263be2afff8e006c05ffceeed/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline 'customer-churn-pipeline' created/updated successfully\n",
      "üìã Version information not available\n",
      "üöÄ Pipeline execution started\n",
      "üìù Execution ARN: arn:aws:sagemaker:eu-central-1:136548476532:pipeline/customer-churn-pipeline/execution/fb9x6y4b874h\n",
      "üìä Status: Executing\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Monitor Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "id": "28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T13:20:28.485505Z",
     "start_time": "2025-10-17T14:17:01.687580Z"
    }
   },
   "source": [
    "# Monitor execution status\n",
    "execution.wait()\n",
    "# while True:\n",
    "#     status = execution.describe()['PipelineExecutionStatus']\n",
    "#     print(f\"Pipeline Status: {status}\")\n",
    "#\n",
    "#     if status in ['Succeeded', 'Failed', 'Stopped']:\n",
    "#         break\n",
    "#\n",
    "#     # Check step statuses\n",
    "#     steps = execution.list_steps()\n",
    "#     for step in steps:\n",
    "#         print(f\"  - {step['StepName']}: {step['StepStatus']}\")\n",
    "#\n",
    "#     time.sleep(30)\n",
    "#     print(\"---\")\n",
    "#\n",
    "# print(f\"\\n‚úÖ Pipeline execution completed with status: {status}\")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Retrieve Pipeline Outputs"
   ]
  },
  {
   "cell_type": "code",
   "id": "30",
   "metadata": {},
   "source": [
    "# Get execution steps details\n",
    "execution_steps = execution.list_steps()\n",
    "\n",
    "for step in execution_steps:\n",
    "    print(f\"\\nStep: {step['StepName']}\")\n",
    "    print(f\"  Status: {step['StepStatus']}\")\n",
    "\n",
    "    if step['StepName'] == 'TrainXGBoostModel' and step['StepStatus'] == 'Succeeded':\n",
    "        # Get training job details\n",
    "        training_job_arn = step['Metadata']['TrainingJob']['Arn']\n",
    "        print(f\"  Training Job ARN: {training_job_arn}\")\n",
    "\n",
    "    elif step['StepName'] == 'CreateXGBoostModel' and step['StepStatus'] == 'Succeeded':\n",
    "        # Get model details\n",
    "        model_arn = step['Metadata']['Model']['Arn']\n",
    "        print(f\"  Model ARN: {model_arn}\")\n",
    "\n",
    "    elif step['StepName'] == 'EvaluateModel' and step['StepStatus'] == 'Succeeded':\n",
    "        outputs = step['Metadata']['ProcessingJob']['ProcessingOutputConfig']['Outputs']\n",
    "        eval_uri = next((o['S3Output']['S3Uri'] for o in outputs if o['OutputName'] == 'evaluation'), None)\n",
    "        if eval_uri:\n",
    "            print(f\"  Evaluation report: {eval_uri}/evaluation.json\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## View Pipeline Execution in SageMaker Studio\n",
    "\n",
    "You can also view and manage your pipeline execution in SageMaker Studio:\n",
    "1. Open SageMaker Studio\n",
    "2. Navigate to the Pipelines section\n",
    "3. Select your pipeline to view execution details, logs, and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Pipeline Version Management (Optional)\n",
    "\n",
    "With SageMaker Pipeline versioning, you can manage different versions of your pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "id": "33",
   "metadata": {},
   "source": [
    "# List all versions of the pipeline\n",
    "try:\n",
    "    versions = pipeline.list_pipeline_versions()\n",
    "    print(f\"üìã Pipeline '{pipeline_name}' versions:\")\n",
    "    for version in versions[:5]:  # Show last 5 versions\n",
    "        print(f\"  - Version {version['PipelineVersion']}: Created {version['CreationTime']}\")\n",
    "        \n",
    "    if len(versions) > 5:\n",
    "        print(f\"  ... and {len(versions) - 5} more versions\")\n",
    "        \n",
    "    # Show how to execute a specific version\n",
    "    print(f\"\\nüí° To execute a specific version:\")\n",
    "    print(f\"   execution = pipeline.start(pipeline_version=1, parameters={{...}})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve version information: {e}\")\n",
    "    print(\"This may be normal for newly created pipelines\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Clean Up Resources (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "id": "35",
   "metadata": {},
   "source": [
    "# # Delete the pipeline (uncomment to execute)\n",
    "# try:\n",
    "#     pipeline.delete()\n",
    "#     print(f\"‚úÖ Pipeline '{pipeline_name}' deleted\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error deleting pipeline: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
