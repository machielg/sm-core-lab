{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# XGBoost Local Training - Customer Churn\n",
    "\n",
    "This notebook demonstrates XGBoost training locally without SageMaker, using the same customer churn dataset from the SageMaker examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_load",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "We'll use the same customer churn dataset preprocessing as the SageMaker examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data - in practice you'd load from S3 or local file\n",
    "# This simulates the churn.txt dataset structure\n",
    "sample_data = '''State,Account Length,Area Code,Phone,Int'l Plan,VMail Plan,VMail Message,Day Mins,Day Calls,Day Charge,Eve Mins,Eve Calls,Eve Charge,Night Mins,Night Calls,Night Charge,Intl Mins,Intl Calls,Intl Charge,CustServ Calls,Churn?\n",
    "KS,128,415,382-4657,no,yes,25,265.1,110,45.07,197.4,99,16.78,244.7,91,11.01,10.0,3,2.70,1,False.\n",
    "OH,107,415,371-7191,no,yes,26,161.6,123,27.47,195.5,103,16.62,254.4,103,11.45,13.7,3,3.70,1,False.\n",
    "NJ,137,415,358-1921,no,no,0,243.4,114,41.38,121.2,110,10.30,162.6,104,7.32,12.2,5,3.29,0,False.\n",
    "OH,84,408,375-9999,yes,no,0,299.4,71,50.90,61.9,88,5.26,196.9,89,8.86,6.6,7,1.78,2,False.'''\n",
    "\n",
    "# For this demo, we'll simulate loading the full dataset\n",
    "# In practice, replace this with: df = pd.read_csv('churn.txt')\n",
    "print(\"Loading customer churn dataset...\")\n",
    "print(\"Dataset structure (first 4 rows):\")\n",
    "df_sample = pd.read_csv(StringIO(sample_data))\n",
    "print(df_sample.head())\n",
    "print(f\"\\nColumns: {list(df_sample.columns)}\")\n",
    "print(f\"Target column 'Churn?' values: {df_sample['Churn?'].unique()}\")\n",
    "\n",
    "# For this notebook, we'll create a larger synthetic dataset based on the structure\n",
    "print(\"\\n[Note: In practice, load the full churn.txt dataset here]\")\n",
    "print(\"[For demo purposes, we'll create synthetic data with the same structure]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset with churn structure for demo\n",
    "np.random.seed(42)\n",
    "n_samples = 3000\n",
    "\n",
    "# Generate synthetic features\n",
    "data = {\n",
    "    'Account Length': np.random.normal(100, 40, n_samples).astype(int),\n",
    "    'VMail Message': np.random.poisson(8, n_samples),\n",
    "    'Day Mins': np.random.normal(180, 50, n_samples),\n",
    "    'Day Calls': np.random.poisson(100, n_samples),\n",
    "    'Eve Mins': np.random.normal(200, 50, n_samples),\n",
    "    'Eve Calls': np.random.poisson(100, n_samples),\n",
    "    'Night Mins': np.random.normal(200, 50, n_samples),\n",
    "    'Night Calls': np.random.poisson(100, n_samples),\n",
    "    'Intl Mins': np.random.normal(10, 3, n_samples),\n",
    "    'Intl Calls': np.random.poisson(4, n_samples),\n",
    "    'CustServ Calls': np.random.poisson(1, n_samples)\n",
    "}\n",
    "\n",
    "# Add categorical features\n",
    "states = ['CA', 'NY', 'TX', 'FL', 'IL', 'PA', 'OH', 'MI', 'NC', 'NJ']\n",
    "area_codes = [408, 415, 510, 650, 707, 925]\n",
    "\n",
    "data['State'] = np.random.choice(states, n_samples)\n",
    "data['Area Code'] = np.random.choice(area_codes, n_samples)\n",
    "data['Int\\'l Plan'] = np.random.choice(['yes', 'no'], n_samples, p=[0.1, 0.9])\n",
    "data['VMail Plan'] = np.random.choice(['yes', 'no'], n_samples, p=[0.3, 0.7])\n",
    "\n",
    "# Create target with some logic (customers with high service calls more likely to churn)\n",
    "churn_prob = 0.1 + 0.3 * (data['CustServ Calls'] > 3) + 0.2 * (data['Day Mins'] > 250)\n",
    "data['Churn?'] = np.random.binomial(1, churn_prob, n_samples)\n",
    "data['Churn?'] = ['True.' if x else 'False.' for x in data['Churn?']]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Created synthetic dataset with {len(df)} samples\")\n",
    "print(f\"Churn distribution: {df['Churn?'].value_counts()}\")\n",
    "print(f\"Churn rate: {(df['Churn?'] == 'True.').mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Same preprocessing steps as the SageMaker example:\n",
    "1. Handle categorical variables\n",
    "2. Remove correlated features\n",
    "3. Create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast Area Code to non-numeric (categorical)\n",
    "df[\"Area Code\"] = df[\"Area Code\"].astype(object)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "model_data = pd.get_dummies(df)\n",
    "print(f\"After one-hot encoding: {model_data.shape}\")\n",
    "\n",
    "# Move target column to the beginning (XGBoost convention)\n",
    "target_col = \"Churn?_True.\"\n",
    "model_data = pd.concat([\n",
    "    model_data[target_col],\n",
    "    model_data.drop([\"Churn?_False.\", \"Churn?_True.\"], axis=1)\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Final dataset shape: {model_data.shape}\")\n",
    "print(f\"Features: {model_data.columns.tolist()[1:6]}...\")  # Show first 5 features\n",
    "print(f\"Target distribution: {model_data[target_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_test_split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation datasets\n",
    "train_data, validation_data = train_test_split(model_data, test_size=0.33, random_state=42, stratify=model_data[target_col])\n",
    "\n",
    "# Further split validation into validation and test\n",
    "validation_data, test_data = train_test_split(validation_data, test_size=0.33, random_state=42, stratify=validation_data[target_col])\n",
    "\n",
    "print(f\"Training set: {train_data.shape}\")\n",
    "print(f\"Validation set: {validation_data.shape}\")\n",
    "print(f\"Test set: {test_data.shape}\")\n",
    "\n",
    "# Prepare data for XGBoost\n",
    "X_train = train_data.drop(target_col, axis=1)\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "X_val = validation_data.drop(target_col, axis=1)\n",
    "y_val = validation_data[target_col]\n",
    "\n",
    "X_test = test_data.drop(target_col, axis=1)\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "print(f\"\\nFeature columns: {X_train.shape[1]}\")\n",
    "print(f\"Training target distribution: {y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgboost_training",
   "metadata": {},
   "source": [
    "## XGBoost Training\n",
    "\n",
    "Now we'll train XGBoost using the native Python API, showing both the high-level sklearn-style interface and the lower-level XGBoost API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgb_sklearn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: XGBoost with sklearn-style API (easiest)\n",
    "print(\"=== Training with XGBoost sklearn-style API ===\")\n",
    "\n",
    "model_sklearn = xgb.XGBClassifier(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.2,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "# Fit with evaluation set\n",
    "model_sklearn.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_names=['train', 'validation'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_sklearn = model_sklearn.predict(X_test)\n",
    "y_proba_sklearn = model_sklearn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\nSklearn-style API Results:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_sklearn):.4f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, y_proba_sklearn):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgb_native",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Native XGBoost API (more control)\n",
    "print(\"\\n=== Training with Native XGBoost API ===\")\n",
    "\n",
    "# Create DMatrix objects\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set parameters (same as sklearn version above)\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.2,  # learning_rate\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Training with validation monitoring\n",
    "evallist = [(dtrain, 'train'), (dval, 'validation')]\n",
    "num_rounds = 100\n",
    "\n",
    "model_native = xgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_rounds, \n",
    "    evallist,\n",
    "    verbose_eval=10  # Print every 10 rounds\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_proba_native = model_native.predict(dtest)\n",
    "y_pred_native = (y_proba_native > 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nNative API Results:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_native):.4f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, y_proba_native):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## Model Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation using the sklearn-style model\n",
    "print(\"=== Detailed Model Evaluation ===\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_sklearn))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_sklearn)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Churn', 'Churn'], \n",
    "            yticklabels=['No Churn', 'Churn'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': model_sklearn.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "sns.barplot(data=top_features, y='feature', x='importance')\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_saving",
   "metadata": {},
   "source": [
    "## Save Model Locally\n",
    "\n",
    "We'll save the model in XGBoost's native format, which is what SageMaker uses internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save sklearn-style model\n",
    "model_sklearn.save_model('models/xgboost_sklearn_model.json')\n",
    "print(\"Saved sklearn-style model to: models/xgboost_sklearn_model.json\")\n",
    "\n",
    "# Save native model (this is the format SageMaker uses)\n",
    "model_native.save_model('models/xgboost_native_model.json')\n",
    "print(\"Saved native model to: models/xgboost_native_model.json\")\n",
    "\n",
    "# Save feature names for later use\n",
    "import json\n",
    "with open('models/feature_names.json', 'w') as f:\n",
    "    json.dump(X_train.columns.tolist(), f)\n",
    "print(\"Saved feature names to: models/feature_names.json\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_type': 'XGBoost',\n",
    "    'n_features': X_train.shape[1],\n",
    "    'n_classes': 2,\n",
    "    'target_column': target_col,\n",
    "    'test_accuracy': float(accuracy_score(y_test, y_pred_sklearn)),\n",
    "    'test_auc': float(roc_auc_score(y_test, y_proba_sklearn)),\n",
    "    'training_samples': len(X_train),\n",
    "    'parameters': {\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.2,\n",
    "        'n_estimators': 100,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"Saved model metadata to: models/model_metadata.json\")\n",
    "\n",
    "print(\"\\n=== Model files saved successfully! ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_and_test",
   "metadata": {},
   "source": [
    "## Load and Test Saved Model\n",
    "\n",
    "Demonstrate loading the saved model and making predictions, simulating what would happen in a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_saved_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model('models/xgboost_native_model.json')\n",
    "\n",
    "# Load feature names\n",
    "with open('models/feature_names.json', 'r') as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "# Load metadata\n",
    "with open('models/model_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"=== Testing Loaded Model ===\")\n",
    "print(f\"Model type: {metadata['model_type']}\")\n",
    "print(f\"Features: {metadata['n_features']}\")\n",
    "print(f\"Training accuracy: {metadata['test_accuracy']:.4f}\")\n",
    "print(f\"Training AUC: {metadata['test_auc']:.4f}\")\n",
    "\n",
    "# Test prediction with loaded model\n",
    "dtest_loaded = xgb.DMatrix(X_test)\n",
    "y_proba_loaded = loaded_model.predict(dtest_loaded)\n",
    "y_pred_loaded = (y_proba_loaded > 0.5).astype(int)\n",
    "\n",
    "# Verify predictions match\n",
    "print(f\"\\nLoaded model test accuracy: {accuracy_score(y_test, y_pred_loaded):.4f}\")\n",
    "print(f\"Loaded model test AUC: {roc_auc_score(y_test, y_proba_loaded):.4f}\")\n",
    "print(f\"Predictions match original model: {np.array_equal(y_pred_native, y_pred_loaded)}\")\n",
    "\n",
    "# Sample prediction\n",
    "sample_customer = X_test.iloc[0:1]\n",
    "sample_prediction = loaded_model.predict(xgb.DMatrix(sample_customer))[0]\n",
    "print(f\"\\nSample customer churn probability: {sample_prediction:.4f}\")\n",
    "print(f\"Sample customer features (first 5): {dict(sample_customer.iloc[0][:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data preprocessing** identical to SageMaker examples\n",
    "2. **Local XGBoost training** using both sklearn-style and native APIs\n",
    "3. **Model evaluation** with metrics and visualizations\n",
    "4. **Model persistence** in XGBoost native format\n",
    "\n",
    "### Key Differences from SageMaker:\n",
    "\n",
    "- **No cloud infrastructure** - runs entirely on local machine\n",
    "- **Direct model access** - no need for endpoints or containers\n",
    "- **Immediate results** - no waiting for training jobs or deployments\n",
    "- **Full control** - access to all XGBoost parameters and features\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Compare results with SageMaker training\n",
    "- Experiment with different hyperparameters locally before SageMaker training\n",
    "- Use this for rapid prototyping and development\n",
    "- Deploy to SageMaker when ready for production scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}