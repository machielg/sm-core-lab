{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SageMaker Core Pipeline - Data Prep, Training, and Model Creation\n",
    "\n",
    "This notebook demonstrates how to create a complete ML pipeline using SageMaker Core that includes:\n",
    "1. Data Processing - Prepare and split the customer churn dataset\n",
    "2. Model Training - Train an XGBoost model on processed data\n",
    "3. Model Evaluation - Evaluate the trained model on holdout data\n",
    "4. Model Creation - Create a deployable SageMaker model from training artifacts"
   ],
   "id": "c577e5a382ec2cd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:41:57.128522Z",
     "start_time": "2025-09-17T07:41:57.101723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "15efd24b255f1468",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize CoreLab Session",
   "id": "e76ffb9d6fca7539"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:41:59.374046Z",
     "start_time": "2025-09-17T07:41:57.137172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from corelab.core.session import CoreLabSession\n",
    "\n",
    "lab_session = CoreLabSession(\n",
    "    'xgboost',\n",
    "    'customer-churn-pipeline',\n",
    "    default_folder='pipeline_notebook',\n",
    "    create_run_folder=True,\n",
    "    aws_profile='sagemaker-role'\n",
    ")\n",
    "lab_session.print()\n",
    "core_session = lab_session.core_session"
   ],
   "id": "5adbfbf3ba5a07ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution role available: arn:aws:iam::136548476532:role/service-role/AmazonSageMaker-ExecutionRole-20250902T164316\n",
      "AWS region: eu-central-1\n",
      "Execution role arn:aws:iam::136548476532:role/service-role/AmazonSageMaker-ExecutionRole-20250902T164316\n",
      "Output bucket uri: s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-09-17T07-41-57\n",
      "Framework: xgboost\n",
      "Project name: customer-churn-pipeline\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import SageMaker Pipeline Components\n",
    "\n",
    "Note: SageMaker Pipelines SDK (not sagemaker-core) is used for pipeline orchestration."
   ],
   "id": "f8a1b5cda9f6c6ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:41:59.426523Z",
     "start_time": "2025-09-17T07:41:59.400084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pipeline-specific imports from SageMaker SDK\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterFloat,\n",
    "    ParameterString\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "# Processing imports - using XGBoostProcessor for better framework integration\n",
    "from sagemaker.xgboost.processing import XGBoostProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "\n",
    "# Training imports  \n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# Model imports\n",
    "from sagemaker.model import Model\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"All pipeline modules imported successfully\")\n"
   ],
   "id": "62410b767c9cc480",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pipeline modules imported successfully\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:41:59.591292Z",
     "start_time": "2025-09-17T07:41:59.436187Z"
    }
   },
   "cell_type": "code",
   "source": "# Create PipelineSession for proper pipeline execution context\npipeline_session = PipelineSession(\n    boto_session=lab_session.core_session.boto_session,\n    default_bucket=lab_session.core_session.default_bucket(),\n    default_bucket_prefix=lab_session.core_session.default_bucket_prefix\n)\n\nprint(f\"üì¶ Default bucket: {pipeline_session.default_bucket()}\")\nprint(f\"üìÅ Bucket prefix: {pipeline_session.default_bucket_prefix}\")",
   "id": "c08c402f774f7aa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Default bucket: sagemaker-eu-central-1-136548476532\n",
      "üìÅ Bucket prefix: pipeline_notebook/2025-09-17T07-41-57\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define input and output locations",
   "id": "5e4ee0283a70ee3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:41:59.627574Z",
     "start_time": "2025-09-17T07:41:59.600863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define data locations\n",
    "data_s3_uri = f\"s3://sagemaker-example-files-prod-{lab_session.region}/datasets/tabular/synthetic/churn.txt\"\n",
    "pipeline_output_s3_uri = lab_session.jobs_output_s3_uri\n",
    "\n",
    "print(f\"üìÅ Data S3 URI: {data_s3_uri}\")\n",
    "print(f\"üì§ Pipeline Output S3 URI: {pipeline_output_s3_uri}\")"
   ],
   "id": "8c6bd50dd386b342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data S3 URI: s3://sagemaker-example-files-prod-eu-central-1/datasets/tabular/synthetic/churn.txt\n",
      "üì§ Pipeline Output S3 URI: s3://sagemaker-eu-central-1-136548476532/pipeline_notebook/2025-09-17T07-41-57/jobs\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Pipeline Parameters\n",
    "\n",
    "Pipeline parameters allow us to customize pipeline executions without modifying the code."
   ],
   "id": "a8b24b715fcdfec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:41:59.664473Z",
     "start_time": "2025-09-17T07:41:59.636372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define pipeline parameters for flexibility\n",
    "\n",
    "# Processing parameters\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "train_test_split = ParameterFloat(\n",
    "    name=\"TrainTestSplit\",\n",
    "    default_value=0.33\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "max_depth = ParameterString(\n",
    "    name=\"MaxDepth\",\n",
    "    default_value=\"5\"\n",
    ")\n",
    "\n",
    "num_round = ParameterString(\n",
    "    name=\"NumRound\",\n",
    "    default_value=\"100\"\n",
    ")\n",
    "\n",
    "print(\"Pipeline parameters defined\")"
   ],
   "id": "7b6066075ff3142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline parameters defined\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1: Define Processing Step\n",
    "\n",
    "This step processes raw data and splits it into train, validation, and test sets."
   ],
   "id": "ea1d2b4c4630160b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:41:59.764799Z",
     "start_time": "2025-09-17T07:41:59.673605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "# Create XGBoostProcessor - framework-aware with better dependency handling\n",
    "xgb_processor = XGBoostProcessor(\n",
    "    framework_version='1.7-1',\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    role=lab_session.role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    env={\"PYTHONUNBUFFERED\": \"1\"},\n",
    "    base_job_name='churn-preprocessing'\n",
    ")\n",
    "\n",
    "src_dir = Path(os.getcwd(), '..', 'processing', 'src').resolve()\n",
    "print(src_dir, src_dir.exists())\n",
    "# Use step_args pattern for proper pipeline integration\n",
    "processor_args = xgb_processor.run(\n",
    "    code=\"preprocessing.py\",\n",
    "    source_dir=str(src_dir) + '/',  # Directory with code and requirements.txt\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=data_s3_uri,\n",
    "            destination=\"/opt/ml/processing/input/data\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            # destination=f\"{pipeline_output_s3_uri}/data/train\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\", \n",
    "            source=\"/opt/ml/processing/output/validation\",\n",
    "            # destination=f\"{pipeline_output_s3_uri}/data/validation\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            # destination=f\"{pipeline_output_s3_uri}/data/test\"\n",
    "        )\n",
    "    ],\n",
    "    arguments=[\"--train-test-split\", train_test_split.to_string()]\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessCustomerChurnData\",\n",
    "    step_args=processor_args\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Processing step defined\")"
   ],
   "id": "57ddf55d0bfe138a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.large.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/machiel/Development/crystalline/sagemaker/corelab/labs/answers/processing/src True\n",
      "‚úÖ Processing step defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/machiel/Development/crystalline/sagemaker/corelab/.venv/lib/python3.13/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define Training Step\n",
    "\n",
    "This step trains an XGBoost model using the processed data from Step 1."
   ],
   "id": "35c383809a789860"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:42:00.221004Z",
     "start_time": "2025-09-17T07:41:59.949308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create XGBoost estimator using generic Estimator with XGBoost image, train.py not needed\n",
    "xgboost_estimator = Estimator(\n",
    "    image_uri=lab_session.retrieve_image('1.7-1'),\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=lab_session.role,\n",
    "    output_path=f\"{pipeline_output_s3_uri}/models\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    hyperparameters={\n",
    "        \"max_depth\": max_depth,\n",
    "        \"eta\": \"0.2\",\n",
    "        \"gamma\": \"4\",\n",
    "        \"min_child_weight\": \"6\",\n",
    "        \"subsample\": \"0.8\",\n",
    "        \"verbosity\": \"0\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": num_round\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use step_args pattern for training step\n",
    "training_args = xgboost_estimator.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainXGBoostModel\",\n",
    "    step_args=training_args\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training step defined\")"
   ],
   "id": "f073e34a1c38bf4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training step defined\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Define Evaluation Step\n",
    "\n",
    "This step evaluates the trained model against the validation dataset created during preprocessing.\n"
   ],
   "id": "8e7f7283f91f455b886aaa450a721eaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create ScriptProcessor for evaluation to run custom metrics\n",
    "evaluation_src_dir = Path(os.getcwd(), 'src').resolve()\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri=lab_session.retrieve_image('1.7-1'),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    role=lab_session.role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    base_job_name='churn-evaluation',\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    env={'PYTHONUNBUFFERED': '1'}\n",
    ")\n",
    "\n",
    "evaluation_args = script_processor.run(\n",
    "    code='evaluate.py',\n",
    "    source_dir=str(evaluation_src_dir) + '/',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/model'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/evaluation'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation',\n",
    "            source='/opt/ml/processing/output'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json'\n",
    ")\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name='EvaluateModel',\n",
    "    step_args=evaluation_args,\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "print('‚úÖ Evaluation step defined')\n"
   ],
   "id": "d93b4fc5e57f401f80e80e09859cef57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Define Model Creation Step\n",
    "\n",
    "This step creates a SageMaker Model from the trained model artifacts."
   ],
   "id": "87f325223b322ae2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:42:00.283971Z",
     "start_time": "2025-09-17T07:42:00.231731Z"
    }
   },
   "cell_type": "code",
   "source": "# Create a Model object using pipeline session for consistency\nmodel = Model(\n    image_uri=lab_session.retrieve_image('1.7-1'),\n    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n    role=lab_session.role,\n    sagemaker_session=pipeline_session\n)\n\n# Use step_args pattern for model creation\nmodel_create_args = model.create(instance_type=\"ml.m5.large\")\n\nstep_create_model = ModelStep(\n    name=\"CreateXGBoostModel\",\n    step_args=model_create_args\n)\n\nprint(\"‚úÖ Model creation step defined\")",
   "id": "44776ea9b47511f7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model creation step defined\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optional: Model Registry Step\n",
    "\n",
    "Register the model in SageMaker Model Registry for versioning and deployment management."
   ],
   "id": "e1bd9523304b434a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:42:00.319883Z",
     "start_time": "2025-09-17T07:42:00.294339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "  model_statistics=MetricsSource(\n",
    "      s3_uri=Join(on=\"/\", values=[\n",
    "          step_evaluate.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "          \"evaluation.json\"\n",
    "      ]),\n",
    "      content_type=\"application/json\"\n",
    "  )\n",
    ")\n",
    "\n",
    "register_args = model.register(content_types=[\"text/csv\"], response_types=[\"text/csv\"],\n",
    "                          inference_instances=[\"ml.m5.large\", \"ml.m5.xlarge\"], transform_instances=[\"ml.m5.large\"],\n",
    "                          model_package_group_name=\"customer-churn-models\", approval_status=\"Approved\",\n",
    "                               model_metrics=model_metrics,\n",
    "                          description=\"XGBoost model for customer churn prediction\")\n",
    "step_register_model = ModelStep(\n",
    "    name=\"RegisterXGBoostModel\",\n",
    "    step_args=register_args\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model registration step defined\")"
   ],
   "id": "d33d215c49688b4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model registration step defined\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create and Execute the Pipeline",
   "id": "49be7fdc950137f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:52:35.910970Z",
     "start_time": "2025-09-17T07:52:35.874374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the pipeline with fixed name for versioning\n",
    "# SageMaker Pipelines now support versioning - use fixed names instead of timestamps\n",
    "pipeline_name = \"customer-churn-pipeline\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        train_test_split,\n",
    "        training_instance_type,\n",
    "        max_depth,\n",
    "        num_round\n",
    "    ],\n",
    "    steps=[\n",
    "        step_process,\n",
    "        step_train,\n",
    "        step_evaluate,\n",
    "        step_create_model,\n",
    "        step_register_model\n",
    "    ],\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Pipeline Name: {pipeline_name}\")\n",
    "print(f\"üìä Pipeline Steps: {len(pipeline.steps)}\")\n",
    "print(\"‚ÑπÔ∏è  Using fixed name - SageMaker will create versions automatically\")\n"
   ],
   "id": "763a931bee96423c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validate Pipeline Definition",
   "id": "d47757da62eedc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:52:39.098334Z",
     "start_time": "2025-09-17T07:52:38.789821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "print('cwd', os.getcwd())\n",
    "# Validate the pipeline definition\n",
    "pipeline_definition = json.loads(pipeline.definition())\n",
    "print(\"Pipeline definition validated successfully!\")\n",
    "print(f\"\\nPipeline has {len(pipeline_definition['Steps'])} steps:\")\n",
    "for step in pipeline_definition['Steps']:\n",
    "    print(f\"  - {step['Name']}: {step['Type']}\")"
   ],
   "id": "3bbdecdc9c35ae98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create/Update and Execute Pipeline",
   "id": "e27f1f9713a34746"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:52:46.569545Z",
     "start_time": "2025-09-17T07:52:45.009858Z"
    }
   },
   "cell_type": "code",
   "source": "# Create/update the pipeline (creates new version if pipeline exists)\nresponse = pipeline.upsert(role_arn=lab_session.role)\nprint(f\"‚úÖ Pipeline '{pipeline_name}' created/updated successfully\")\n\n# Check if this created a new version\ntry:\n    versions = pipeline.list_pipeline_versions()\n    version_count = len(versions)\n    latest_version = versions[0]['PipelineVersion'] if versions else 1\n    print(f\"üìã Pipeline now has {version_count} version(s), latest: v{latest_version}\")\nexcept:\n    print(\"üìã Version information not available\")\n\n# Start pipeline execution\nexecution = pipeline.start(\n    parameters={\n        \"ProcessingInstanceType\": \"ml.m5.large\",\n        \"TrainingInstanceType\": \"ml.m5.large\", \n        \"TrainTestSplit\": 0.33,\n        \"MaxDepth\": \"5\",\n        \"NumRound\": \"100\"\n    }\n)\n\nprint(\"üöÄ Pipeline execution started\")\nprint(f\"üìù Execution ARN: {execution.arn}\")\nprint(f\"üìä Status: {execution.describe()['PipelineExecutionStatus']}\")",
   "id": "6b751fede2e45938",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Monitor Pipeline Execution",
   "id": "34a5e677045a7b82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:50:05.539134Z",
     "start_time": "2025-09-17T07:42:01.966850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Monitor execution status\n",
    "execution.wait()\n",
    "# while True:\n",
    "#     status = execution.describe()['PipelineExecutionStatus']\n",
    "#     print(f\"Pipeline Status: {status}\")\n",
    "#\n",
    "#     if status in ['Succeeded', 'Failed', 'Stopped']:\n",
    "#         break\n",
    "#\n",
    "#     # Check step statuses\n",
    "#     steps = execution.list_steps()\n",
    "#     for step in steps:\n",
    "#         print(f\"  - {step['StepName']}: {step['StepStatus']}\")\n",
    "#\n",
    "#     time.sleep(30)\n",
    "#     print(\"---\")\n",
    "#\n",
    "# print(f\"\\n‚úÖ Pipeline execution completed with status: {status}\")"
   ],
   "id": "7dba6cd26c9b0b0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retrieve Pipeline Outputs",
   "id": "56c38d43056c7de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:50:05.840697Z",
     "start_time": "2025-09-17T07:50:05.637044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get execution steps details\n",
    "execution_steps = execution.list_steps()\n",
    "\n",
    "for step in execution_steps:\n",
    "    print(f\"\\nStep: {step['StepName']}\")\n",
    "    print(f\"  Status: {step['StepStatus']}\")\n",
    "\n",
    "    if step['StepName'] == 'TrainXGBoostModel' and step['StepStatus'] == 'Succeeded':\n",
    "        # Get training job details\n",
    "        training_job_arn = step['Metadata']['TrainingJob']['Arn']\n",
    "        print(f\"  Training Job ARN: {training_job_arn}\")\n",
    "\n",
    "    elif step['StepName'] == 'CreateXGBoostModel' and step['StepStatus'] == 'Succeeded':\n",
    "        # Get model details\n",
    "        model_arn = step['Metadata']['Model']['Arn']\n",
    "        print(f\"  Model ARN: {model_arn}\")\n",
    "\n",
    "    elif step['StepName'] == 'EvaluateModel' and step['StepStatus'] == 'Succeeded':\n",
    "        outputs = step['Metadata']['ProcessingJob']['ProcessingOutputConfig']['Outputs']\n",
    "        eval_uri = next((o['S3Output']['S3Uri'] for o in outputs if o['OutputName'] == 'evaluation'), None)\n",
    "        if eval_uri:\n",
    "            print(f\"  Evaluation report: {eval_uri}/evaluation.json\")\n"
   ],
   "id": "d07b2dcd40ab706c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## View Pipeline Execution in SageMaker Studio\n",
    "\n",
    "You can also view and manage your pipeline execution in SageMaker Studio:\n",
    "1. Open SageMaker Studio\n",
    "2. Navigate to the Pipelines section\n",
    "3. Select your pipeline to view execution details, logs, and metrics"
   ],
   "id": "7782f74faa1afc1e"
  },
  {
   "cell_type": "markdown",
   "id": "qz4twexi2f",
   "source": "## Pipeline Version Management (Optional)\n\nWith SageMaker Pipeline versioning, you can manage different versions of your pipeline:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zc4h4842rfl",
   "source": "# List all versions of the pipeline\ntry:\n    versions = pipeline.list_pipeline_versions()\n    print(f\"üìã Pipeline '{pipeline_name}' versions:\")\n    for version in versions[:5]:  # Show last 5 versions\n        print(f\"  - Version {version['PipelineVersion']}: Created {version['CreationTime']}\")\n        \n    if len(versions) > 5:\n        print(f\"  ... and {len(versions) - 5} more versions\")\n        \n    # Show how to execute a specific version\n    print(f\"\\nüí° To execute a specific version:\")\n    print(f\"   execution = pipeline.start(pipeline_version=1, parameters={{...}})\")\n    \nexcept Exception as e:\n    print(f\"Could not retrieve version information: {e}\")\n    print(\"This may be normal for newly created pipelines\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:50:06.143926Z",
     "start_time": "2025-09-17T07:50:05.848419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Pipeline 'customer-churn-pipeline' versions:\n",
      "Could not retrieve version information: slice(None, 5, None)\n",
      "This may be normal for newly created pipelines\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean Up Resources (Optional)",
   "id": "690c17c7f211e6ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T07:50:06.175033Z",
     "start_time": "2025-09-17T07:50:06.150321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Delete the pipeline (uncomment to execute)\n",
    "# try:\n",
    "#     pipeline.delete()\n",
    "#     print(f\"‚úÖ Pipeline '{pipeline_name}' deleted\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error deleting pipeline: {e}\")"
   ],
   "id": "13a280d62bccc3e5",
   "outputs": [],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
