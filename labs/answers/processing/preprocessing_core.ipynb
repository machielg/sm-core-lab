{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corelab.core.session import CoreLabSession\n",
    "lab_session = CoreLabSession('xgboost', 'customer-churn', default_folder='processing_notebook', create_run_folder=True, aws_profile='sagemaker-role')\n",
    "lab_session.print()\n",
    "core_session = lab_session.core_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete sagemaker-core imports\n",
    "from sagemaker_core.main.shapes import (\n",
    "    AppSpecification, \n",
    "    ProcessingResources, \n",
    "    ProcessingInput, \n",
    "    ProcessingClusterConfig,\n",
    "    ProcessingOutput,\n",
    "    ProcessingOutputConfig,\n",
    "    ProcessingStoppingCondition,\n",
    "    ProcessingS3Input,\n",
    "    ProcessingS3Output\n",
    ")\n",
    "from sagemaker_core.main.resources import ProcessingJob\n",
    "\n",
    "print(\"All sagemaker-core modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def upload_code_and_data():\n",
    "    print(\"cwd:\", os.getcwd())\n",
    "    code = lab_session.upload_file('src', 'preprocessing.py', 'prepare-churn-code')\n",
    "    # Define data and output URIs\n",
    "    data = f\"s3://sagemaker-example-files-prod-{lab_session.region}/datasets/tabular/synthetic/churn.txt\"\n",
    "    output = lab_session.jobs_output_s3_uri\n",
    "\n",
    "    return code, data, output\n",
    "\n",
    "upload_code_and_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the Processing Job using sagemaker-core\n",
    "code_s3_uri, data_s3_uri, output_s3_uri = upload_code_and_data()\n",
    "\n",
    "print(f\"üìÇ Code S3 URI: {code_s3_uri}\")\n",
    "print(f\"üìÅ Data S3 URI: {data_s3_uri}\")\n",
    "print(f\"üì§ Output S3 URI: {output_s3_uri}\")\n",
    "\n",
    "job_name = lab_session.processing_job_name\n",
    "job = ProcessingJob.create(\n",
    "    processing_job_name=job_name,\n",
    "    role_arn=lab_session.role,\n",
    "    session=lab_session.core_session.boto_session,\n",
    "    region=lab_session.region,\n",
    "    app_specification=AppSpecification(\n",
    "        image_uri=lab_session.retrieve_image('1.7-1'),\n",
    "        container_entrypoint=[\"python3\", \"/opt/ml/processing/input/code/preprocessing.py\"],\n",
    "        container_arguments=[\"--train-test-split\", \"0.33\"]\n",
    "    ),\n",
    "    processing_resources=ProcessingResources(\n",
    "        cluster_config=ProcessingClusterConfig(\n",
    "            instance_type=\"ml.m5.large\",\n",
    "            instance_count=1,\n",
    "            volume_size_in_gb=30\n",
    "        )\n",
    "    ),\n",
    "    processing_inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name=\"code\",\n",
    "            app_managed=False,\n",
    "            s3_input=ProcessingS3Input(\n",
    "                s3_uri=code_s3_uri,\n",
    "                local_path=\"/opt/ml/processing/input/code\",\n",
    "                s3_data_type=\"S3Prefix\",\n",
    "                s3_input_mode=\"File\"\n",
    "            )\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            input_name=\"data\",\n",
    "            app_managed=False,\n",
    "            s3_input=ProcessingS3Input(\n",
    "                s3_uri=data_s3_uri,\n",
    "                local_path=\"/opt/ml/processing/input/data\",\n",
    "                s3_data_type=\"S3Prefix\",\n",
    "                s3_input_mode=\"File\"\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    processing_output_config=ProcessingOutputConfig(\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"processed\",\n",
    "                app_managed=False,\n",
    "                s3_output=ProcessingS3Output(\n",
    "                    s3_uri=output_s3_uri + '/' + job_name,\n",
    "                    local_path=\"/opt/ml/processing/output\",\n",
    "                    s3_upload_mode=\"EndOfJob\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    environment={\"PYTHONUNBUFFERED\": \"1\"},\n",
    "    stopping_condition=ProcessingStoppingCondition(\n",
    "        max_runtime_in_seconds=3600\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Created Processing Job: {job.processing_job_name}\")\n",
    "print(f\"üìä Initial Status: {job.processing_job_status}\")\n",
    "\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Alternative: Using XGBoostProcessor from Standard SageMaker SDK\n",
    "\n",
    "The same processing job can be accomplished using the XGBoostProcessor, which provides better framework integration and dependency management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach using XGBoostProcessor from standard SageMaker SDK\n",
    "from sagemaker.xgboost.processing import XGBoostProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Define data locations (reuse from above)\n",
    "data_s3_uri = f\"s3://sagemaker-example-files-prod-{lab_session.region}/datasets/tabular/synthetic/churn.txt\"\n",
    "output_s3_uri = lab_session.jobs_output_s3_uri\n",
    "\n",
    "print(f\"üìÅ Data S3 URI: {data_s3_uri}\")\n",
    "print(f\"üì§ Output S3 URI: {output_s3_uri}\")\n",
    "\n",
    "# Create XGBoostProcessor - framework-aware with better dependency handling\n",
    "xgb_processor = XGBoostProcessor(\n",
    "    framework_version='1.7-1',\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    role=lab_session.role,\n",
    "    sagemaker_session=lab_session.get_sagemaker_session(),\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    env={\"PYTHONUNBUFFERED\": \"1\"}\n",
    ")\n",
    "\n",
    "# Run the processing job with framework features\n",
    "job_name = lab_session.processing_job_name + \"-xgb\"\n",
    "\n",
    "xgb_processor.run(\n",
    "    code=\"preprocessing.py\",         # Entry point script\n",
    "    source_dir=\"src/\",              # Directory with code and requirements.txt\n",
    "    job_name=job_name,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=data_s3_uri,\n",
    "            destination=\"/opt/ml/processing/input/data\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"processed\",\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=f\"{output_s3_uri}/{job_name}\"\n",
    "        )\n",
    "    ],\n",
    "    arguments=[\"--train-test-split\", \"0.33\"],\n",
    "    wait=True,  # Wait for completion\n",
    "    logs=True   # Stream logs to notebook\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ XGBoost Processing job completed: {job_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Comparison: SageMaker Core vs XGBoostProcessor\n",
    "\n",
    "**SageMaker Core (ProcessingJob):**\n",
    "- ‚úÖ More explicit configuration with shapes\n",
    "- ‚úÖ Fine-grained control over all parameters\n",
    "- ‚úÖ Type-safe with structured objects\n",
    "- ‚úÖ Direct API mapping to AWS service\n",
    "- ‚ùå More verbose syntax\n",
    "- ‚ùå Manual status polling with `.wait()`\n",
    "- ‚ùå No automatic dependency installation\n",
    "\n",
    "**XGBoostProcessor (Standard SDK):**\n",
    "- ‚úÖ Framework-optimized for XGBoost workflows\n",
    "- ‚úÖ Automatic requirements.txt installation via `source_dir`\n",
    "- ‚úÖ Built-in log streaming with `logs=True`\n",
    "- ‚úÖ Automatic wait with `wait=True`\n",
    "- ‚úÖ Supports `dependencies` parameter for additional files\n",
    "- ‚úÖ Same XGBoost image as training (consistency)\n",
    "- ‚ùå Framework-specific (not general purpose)\n",
    "\n",
    "**Key Advantage:** XGBoostProcessor handles dependencies automatically, making it ideal for XGBoost-based data processing workflows where you need additional Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
