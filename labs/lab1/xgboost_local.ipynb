{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# XGBoost Local Training - Customer Churn\n",
    "\n",
    "This notebook demonstrates XGBoost training locally without SageMaker, using the same customer churn dataset from the SageMaker examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:24:00.875361Z",
     "start_time": "2025-10-01T13:24:00.527925Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "We'll use the same customer churn dataset preprocessing as the SageMaker examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:24:07.369341Z",
     "start_time": "2025-10-01T13:24:07.282459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the customer churn dataset\n",
    "print(\"Loading customer churn dataset...\")\n",
    "df = pd.read_csv('churn.csv.bz2', compression='bz2')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTarget column 'Churn?' values: {df['Churn?'].unique()}\")\n",
    "print(f\"Churn rate: {(df['Churn?'] == 'True.').mean():.2%}\")\n",
    "\n",
    "# Basic dataset info\n",
    "print(\"\\nDataset info:\")\n",
    "print(f\"- Total samples: {len(df)}\")\n",
    "print(f\"- Features: {df.shape[1] - 1}\")  # Minus target column\n",
    "print(f\"- Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"- Churned customers: {(df['Churn?'] == 'True.').sum()}\")\n",
    "print(f\"- Retained customers: {(df['Churn?'] == 'False.').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Same preprocessing steps as the SageMaker example:\n",
    "1. Handle categorical variables\n",
    "2. Remove correlated features\n",
    "3. Create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:24:11.299672Z",
     "start_time": "2025-10-01T13:24:11.192676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cast Area Code to non-numeric (categorical)\n",
    "df[\"Area Code\"] = df[\"Area Code\"].astype(object)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "model_data = pd.get_dummies(df)\n",
    "print(f\"After one-hot encoding: {model_data.shape}\")\n",
    "\n",
    "# Move target column to the beginning (XGBoost convention)\n",
    "target_col = \"Churn?_True.\"\n",
    "model_data = pd.concat([\n",
    "    model_data[target_col],\n",
    "    model_data.drop([\"Churn?_False.\", \"Churn?_True.\"], axis=1)\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Final dataset shape: {model_data.shape}\")\n",
    "print(f\"Features: {model_data.columns.tolist()[1:6]}...\")  # Show first 5 features\n",
    "print(f\"Target distribution: {model_data[target_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:24:13.775090Z",
     "start_time": "2025-10-01T13:24:13.710566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into train and validation datasets\n",
    "train_data, validation_data = train_test_split(model_data, test_size=0.33, random_state=42, stratify=model_data[target_col])\n",
    "\n",
    "# Further split validation into validation and test\n",
    "validation_data, test_data = train_test_split(validation_data, test_size=0.33, random_state=42, stratify=validation_data[target_col])\n",
    "\n",
    "print(f\"Training set: {train_data.shape}\")\n",
    "print(f\"Validation set: {validation_data.shape}\")\n",
    "print(f\"Test set: {test_data.shape}\")\n",
    "\n",
    "# Prepare data for XGBoost\n",
    "X_train = train_data.drop(target_col, axis=1)\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "X_val = validation_data.drop(target_col, axis=1)\n",
    "y_val = validation_data[target_col]\n",
    "\n",
    "X_test = test_data.drop(target_col, axis=1)\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "print(f\"\\nFeature columns: {X_train.shape[1]}\")\n",
    "print(f\"Training target distribution: {y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## XGBoost Training\n",
    "\n",
    "Now we'll train XGBoost using the native Python API, showing both the high-level sklearn-style interface and the lower-level XGBoost API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:24:38.037800Z",
     "start_time": "2025-10-01T13:24:22.417300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Method 1: XGBoost with sklearn-style API (easiest)\n",
    "print(\"=== Training with XGBoost sklearn-style API ===\")\n",
    "\n",
    "model_sklearn = xgb.XGBClassifier(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.2,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "# Fit with evaluation set (evaluation sets will be named validation_0, validation_1, etc.)\n",
    "model_sklearn.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_sklearn = model_sklearn.predict(X_test)\n",
    "y_proba_sklearn = model_sklearn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nSklearn-style API Results:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_sklearn):.4f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, y_proba_sklearn):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:24:58.567336Z",
     "start_time": "2025-10-01T13:24:43.076296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Method 2: Native XGBoost API (more control)\n",
    "print(\"\\n=== Training with Native XGBoost API ===\")\n",
    "\n",
    "# Create DMatrix objects\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set parameters (same as sklearn version above)\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.2,  # learning_rate\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Training with validation monitoring\n",
    "evallist = [(dtrain, 'train'), (dval, 'validation')]\n",
    "num_rounds = 100\n",
    "\n",
    "model_native = xgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_rounds, \n",
    "    evallist,\n",
    "    verbose_eval=10  # Print every 10 rounds\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_proba_native = model_native.predict(dtest)\n",
    "y_pred_native = (y_proba_native > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nNative API Results:\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_native):.4f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, y_proba_native):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Model Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:25:00.482161Z",
     "start_time": "2025-10-01T13:24:59.895873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Detailed evaluation - use sklearn model if available, otherwise use native model\n",
    "print(\"=== Detailed Model Evaluation ===\")\n",
    "\n",
    "# Check which model is available for evaluation\n",
    "try:\n",
    "    # Try to use sklearn model predictions if they exist\n",
    "    test_predictions = y_pred_sklearn\n",
    "    test_probabilities = y_proba_sklearn\n",
    "    eval_model = model_sklearn\n",
    "    model_type = \"sklearn-style\"\n",
    "    print(\"Using sklearn-style model for evaluation\")\n",
    "except NameError:\n",
    "    # Fall back to native model if sklearn model failed\n",
    "    test_predictions = y_pred_native\n",
    "    test_probabilities = y_proba_native\n",
    "    eval_model = None  # Native model doesn't have feature_importances_ attribute\n",
    "    model_type = \"native\"\n",
    "    print(\"Using native XGBoost model for evaluation\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nClassification Report ({model_type} model):\")\n",
    "print(classification_report(y_test, test_predictions))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Churn', 'Churn'], \n",
    "            yticklabels=['No Churn', 'Churn'])\n",
    "plt.title(f'Confusion Matrix ({model_type} model)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance (only available for sklearn model)\n",
    "if model_type == \"sklearn-style\":\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': eval_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    sns.barplot(data=top_features, y='feature', x='importance')\n",
    "    plt.title('Top 15 Feature Importances (sklearn-style model)')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "else:\n",
    "    # For native model, get feature importance differently\n",
    "    feature_importance = model_native.get_score(importance_type='weight')\n",
    "    feature_importance_df = pd.DataFrame(\n",
    "        list(feature_importance.items()), \n",
    "        columns=['feature', 'importance']\n",
    "    ).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance_df.head(15)\n",
    "    sns.barplot(data=top_features, y='feature', x='importance')\n",
    "    plt.title('Top 15 Feature Importances (native model)')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Save Model Locally\n",
    "\n",
    "We'll save the model in XGBoost's native format, which is what SageMaker uses internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T13:43:21.461294Z",
     "start_time": "2025-10-01T13:43:21.426964Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save sklearn-style model if it was successfully trained\n",
    "sklearn_model_saved = False\n",
    "try:\n",
    "    model_sklearn.save_model('models/xgboost_sklearn_model.json')\n",
    "    print(\"Saved sklearn-style model to: models/xgboost_sklearn_model.json\")\n",
    "    sklearn_model_saved = True\n",
    "except (NameError, AttributeError) as e:\n",
    "    print(f\"Sklearn model not available for saving: {e}\")\n",
    "    print(\"This can happen if the sklearn training failed, but native model should still be available.\")\n",
    "\n",
    "# Save native model (this is the format SageMaker uses)\n",
    "model_native.save_model('models/xgboost_native_model.json')\n",
    "print(\"Saved native model to: models/xgboost_native_model.json\")\n",
    "\n",
    "# Save feature names for later use\n",
    "with open('models/feature_names.json', 'w') as f:\n",
    "    json.dump(X_train.columns.tolist(), f)\n",
    "print(\"Saved feature names to: models/feature_names.json\")\n",
    "\n",
    "# Save model metadata - use available model results\n",
    "try:\n",
    "    # Prefer sklearn model results if available\n",
    "    test_accuracy = float(accuracy_score(y_test, y_pred_sklearn))\n",
    "    test_auc = float(roc_auc_score(y_test, y_proba_sklearn))\n",
    "    model_source = \"sklearn\"\n",
    "except NameError:\n",
    "    # Use native model results as fallback\n",
    "    test_accuracy = float(accuracy_score(y_test, y_pred_native))\n",
    "    test_auc = float(roc_auc_score(y_test, y_proba_native))\n",
    "    model_source = \"native\"\n",
    "\n",
    "metadata = {\n",
    "    'model_type': 'XGBoost',\n",
    "    'n_features': X_train.shape[1],\n",
    "    'n_classes': 2,\n",
    "    'target_column': target_col,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_auc': test_auc,\n",
    "    'training_samples': len(X_train),\n",
    "    'model_source': model_source,  # Track which model provided the results\n",
    "    'sklearn_saved': sklearn_model_saved,\n",
    "    'parameters': {\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.2,\n",
    "        'n_estimators': 100,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"Saved model metadata to: models/model_metadata.json\")\n",
    "\n",
    "print(\"\\n=== Model files saved successfully! ===\")\n",
    "print(f\"Results based on {model_source} model\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Load and Test Saved Model\n",
    "\n",
    "Demonstrate loading the saved model and making predictions, simulating what would happen in a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model('models/xgboost_native_model.json')\n",
    "\n",
    "# Load feature names\n",
    "with open('models/feature_names.json', 'r') as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "# Load metadata\n",
    "with open('models/model_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"=== Testing Loaded Model ===\")\n",
    "print(f\"Model type: {metadata['model_type']}\")\n",
    "print(f\"Features: {metadata['n_features']}\")\n",
    "print(f\"Training accuracy: {metadata['test_accuracy']:.4f}\")\n",
    "print(f\"Training AUC: {metadata['test_auc']:.4f}\")\n",
    "\n",
    "# Test prediction with loaded model\n",
    "dtest_loaded = xgb.DMatrix(X_test)\n",
    "y_proba_loaded = loaded_model.predict(dtest_loaded)\n",
    "y_pred_loaded = (y_proba_loaded > 0.5).astype(int)\n",
    "\n",
    "# Verify predictions match\n",
    "print(f\"\\nLoaded model test accuracy: {accuracy_score(y_test, y_pred_loaded):.4f}\")\n",
    "print(f\"Loaded model test AUC: {roc_auc_score(y_test, y_proba_loaded):.4f}\")\n",
    "print(f\"Predictions match original model: {np.array_equal(y_pred_native, y_pred_loaded)}\")\n",
    "\n",
    "# Sample prediction\n",
    "sample_customer = X_test.iloc[0:1]\n",
    "sample_prediction = loaded_model.predict(xgb.DMatrix(sample_customer))[0]\n",
    "print(f\"\\nSample customer churn probability: {sample_prediction:.4f}\")\n",
    "print(f\"Sample customer features (first 5): {dict(sample_customer.iloc[0][:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data preprocessing** identical to SageMaker examples\n",
    "2. **Local XGBoost training** using both sklearn-style and native APIs\n",
    "3. **Model evaluation** with metrics and visualizations\n",
    "4. **Model persistence** in XGBoost native format\n",
    "\n",
    "### Key Differences from SageMaker:\n",
    "\n",
    "- **No cloud infrastructure** - runs entirely on local machine\n",
    "- **Direct model access** - no need for endpoints or containers\n",
    "- **Immediate results** - no waiting for training jobs or deployments\n",
    "- **Full control** - access to all XGBoost parameters and features\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Compare results with SageMaker training\n",
    "- Experiment with different hyperparameters locally before SageMaker training\n",
    "- Use this for rapid prototyping and development\n",
    "- Deploy to SageMaker when ready for production scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
